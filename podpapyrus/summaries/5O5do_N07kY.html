<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>The Computer Chip Could End Nvidia&#39;s AI Monopoly | Guillaume Verdon on Extropic PodPapyrus</title>
    <link rel="icon" type="image/png" href="../logo256.png" />
    <link rel="apple-touch-icon" href="../logo256.png" />

    <link rel="canonical" href="https://andrewarrow.dev/podpapyrus/summaries/5O5do_N07kY.html">

    
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://podpapyrus.com/" />
    <meta property="og:title" content="The Computer Chip Could End Nvidia&#39;s AI Monopoly | Guillaume Verdon on Extropic - PodPapyrus." />
    <meta property="og:description" content="The Computer Chip Could End Nvidia&#39;s AI Monopoly | Guillaume Verdon on Extropic PodPapyrus." />
    <meta property="og:image" content="https://andrewarrow.dev/podpapyrus/images/5O5do_N07kY.jpg" />
          
    
    <meta property="twitter:card" content="summary_large_image" />
    <meta property="twitter:url" content="https://podpapyrus.com/" />
    <meta property="twitter:title" content="The Computer Chip Could End Nvidia&#39;s AI Monopoly | Guillaume Verdon on Extropic PodPapyrus." />
    <meta property="twitter:description" content="PodPapyrus PodPapyrus." />
    <meta property="twitter:image" content="https://andrewarrow.dev/podpapyrus/images/5O5do_N07kY.jpg" />
    
    <script src="https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4"></script>
    <script type="text/javascript">
  (function (f, b) { if (!b.__SV) { var e, g, i, h; window.mixpanel = b; b._i = []; b.init = function (e, f, c) { function g(a, d) { var b = d.split("."); 2 == b.length && ((a = a[b[0]]), (d = b[1])); a[d] = function () { a.push([d].concat(Array.prototype.slice.call(arguments, 0))); }; } var a = b; "undefined" !== typeof c ? (a = b[c] = []) : (c = "mixpanel"); a.people = a.people || []; a.toString = function (a) { var d = "mixpanel"; "mixpanel" !== c && (d += "." + c); a || (d += " (stub)"); return d; }; a.people.toString = function () { return a.toString(1) + ".people (stub)"; }; i = "disable time_event track track_pageview track_links track_forms track_with_groups add_group set_group remove_group register register_once alias unregister identify name_tag set_config reset opt_in_tracking opt_out_tracking has_opted_in_tracking has_opted_out_tracking clear_opt_in_out_tracking start_batch_senders people.set people.set_once people.unset people.increment people.append people.union people.track_charge people.clear_charges people.delete_user people.remove".split( " "); for (h = 0; h < i.length; h++) g(a, i[h]); var j = "set set_once union unset remove delete".split(" "); a.get_group = function () { function b(c) { d[c] = function () { call2_args = arguments; call2 = [c].concat(Array.prototype.slice.call(call2_args, 0)); a.push([e, call2]); }; } for ( var d = {}, e = ["get_group"].concat( Array.prototype.slice.call(arguments, 0)), c = 0; c < j.length; c++) b(j[c]); return d; }; b._i.push([e, f, c]); }; b.__SV = 1.2; e = f.createElement("script"); e.type = "text/javascript"; e.async = !0; e.src = "undefined" !== typeof MIXPANEL_CUSTOM_LIB_URL ? MIXPANEL_CUSTOM_LIB_URL : "file:" === f.location.protocol && "//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js".match(/^\/\//) ? "https://cdn.mxpnl.com/libs/mixpanel-2-latest.min.js" : "//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js"; g = f.getElementsByTagName("script")[0]; g.parentNode.insertBefore(e, g); } })(document, window.mixpanel || []);

mixpanel.init("29d6db85517ba504818659df83844c01", {
  track_pageview: true,
  persistence: "localStorage",
});

</script>

  </head>
  <body class="bg-gray-900 text-gray-100">
    
    <nav class="bg-gray-800 shadow-lg fixed w-full z-50">
      <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="flex justify-between h-16">
          <div class="flex items-center">
            <div class="flex-shrink-0 flex items-center">
              <a href="../index.html" class="text-2xl font-bold text-blue-400">
              <img src="../logo256.png" alt="PodPapyrus" class="h-8 w-8 mr-3" />
              </a>
            </div>
          </div>
          <div class="hidden md:flex items-center space-x-8">
          </div>
        </div>
      </div>
    </nav>

    
    <section class="pt-20 pb-8 bg-gradient-to-br from-gray-800 to-gray-900">
      <div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-8">
          <img src="../images/5O5do_N07kY.jpg" alt="The Computer Chip Could End Nvidia&#39;s AI Monopoly | Guillaume Verdon on Extropic" class="w-48 h-32 object-cover rounded-lg mx-auto mb-6" />
          <span class="text-blue-400 text-sm font-medium">Great Pods</span>
          <h1 class="text-3xl md:text-4xl font-bold text-gray-100 mt-2 mb-4">
            The Computer Chip Could End Nvidia&#39;s AI Monopoly | Guillaume Verdon on Extropic
          </h1>
        </div>
      </div>
    </section>

    
    <section class="py-8 bg-gray-900">
      <div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8">
        
        <div class="bg-green-900 rounded-lg p-8 border border-green-700 mb-8">
          <h2 class="text-2xl font-bold text-green-100 mb-4">Key Points</h2>
          <div class="prose prose-invert max-w-none prose-li:list-disc prose-ul:list-disc">
            <div class="text-green-50 [&_ul]:list-disc [&_li]:list-item [&_ul]:ml-6"><ul>
<li>Companies controlling AI extensions of human brains could steer thinking and control people by proxy, creating fundamental risk</li>
<li>Extropic is developing thermodynamic computing using new silicon primitives based on stochastic electronics and bioinspired physics</li>
<li>Current AI workloads are probabilistic, making probabilistic hardware a natural fit compared to traditional deterministic computers</li>
<li>The company has progressed from algorithmic concepts to manufactured silicon chips in just 2-3 years</li>
<li>Their approach uses programmable electron diffusion controlled by voltages, allowing fractional bit operations instead of just on/off states</li>
<li>First systems could be 1,000x more energy efficient than GPUs, potentially reaching 100,000x efficiency at chip level</li>
<li>Technology could democratize AI by enabling personal AI computers instead of requiring massive centralized data centers</li>
<li>Current AI concentration in few companies/countries creates power asymmetries and risks of technological tyranny</li>
<li>Decentralization of AI power is necessary for innovation, fault tolerance, and preventing regulatory capture</li>
<li>The effective accelerationist (e/acc) movement promotes technological progress over precautionary approaches to AI development</li>
<li>Competition between US and China is driving AI acceleration, with benefits flowing to other nations through open-source releases</li>
<li>Energy demands for AI are becoming extreme - single data center sites requiring more power than major cities</li>
<li>Biotech represents the next major frontier after semiconductors and AI, requiring deregulation and acceleration</li>
<li>Future involves merging biological and silicon substrates rather than replacement of humans by AI</li>
<li>Intelligence exists across multiple scales from quantum to cosmic, with thermodynamic principles governing self-organization</li>
<li>Systems and cultures oriented toward growth succeed evolutionarily, while those opposing progress get pruned out</li>
<li>Open-source AI models are essential for preventing monopolization and ensuring broader access to AI capabilities</li>
<li>Manufacturing at scale using standard fab processes is crucial for any new computing paradigm to succeed commercially</li>
</ul>
</div>
          </div>
        </div>

        
        <div class="bg-gray-800 rounded-lg p-8 border border-gray-700">
          <h2 class="text-2xl font-bold text-gray-100 mb-4">Full Transcript</h2>
          <textarea readonly class="w-full h-96 bg-gray-700 text-gray-100 border border-gray-600 rounded-lg p-4 resize-y font-mono text-sm leading-relaxed">Language: en
If a set of companies control the
extension of your brain and it&#39;s like
the collective extension of our brain,
then they could just like steer it to
think a certain way and and now they
kind of control you by proxy. And to me,
I think that&#39;s like that&#39;s fundamentally
risky. And so we kind of have to to arm
the rebels.
We are joined today by an internet
legend and possibly a computing legend
in in the making. Uh Guom Verdon,
although I hear I hear you say Verden.
Verden. Yeah. But you&#39;re French
Canadian, right? Or or That&#39;s right.
Yeah. So I I don&#39;t know how do you
prefer people to say it. Yeah. I mean
the the proper way to say it is like
It&#39;s like it&#39;s French, but I was going
to lean in, but then I heard you say it
somewhere else and I didn&#39;t know I
didn&#39;t know if I should be leaning in.
Um, and also known as as Beth Jesus.
Yep. Yep. That&#39;s my pseudonym. Yes. U
which we will we will get into. And just
before we get too far, um I want to
thank E1 Ventures for sponsoring our
podcast. We actually have E1 Ventures
representatives here today to watch the
show. Um, so they&#39;ve been kind enough to
sponsor our show and um, I guess maybe
full disclosure, this was a coincidence,
but I think you&#39;re actually an investor
in your company in Extropic. Um, I
didn&#39;t didn&#39;t know this was happening
when we when we invited you on. There
you go. Yeah. Um, well, thanks so much
for coming in, man. Yeah, super happy to
be here. It&#39;s an honor. I feel Oh, that
that was way too far. Um the I feel like
there&#39;s two giant buckets we can get
into which is obviously the EAC the
effective accelerationist movement and
then Extropic your company and they both
take some unpacking. Um why don&#39;t we
just real we&#39;ll come back to it more in
more detail as we get on but let&#39;s let&#39;s
do extropic a little bit first just to
give people a frame of where you&#39;re
coming from and um I&#39;ll take a crack and
then you can fix everything I mess up
but um whole new field of whole new
approach to computing definitely um
angled at AI but not just AI and it&#39;s so
it&#39;s called thermodynamic computing.
That&#39;s right. Different to quantum, very
different to our traditional bits. Um,
is there a way to explain it that
that just about everybody can can
understand? Essentially, what we&#39;re
doing um is we&#39;re we&#39;re creating new
primitives uh in what is called
stochastic electronics or bioinspired
electronics. Um so it&#39;s new silicon
primitives. It&#39;s not just an
architecture. We&#39;re not just taking
floating point arithmetic and memory and
changing the configuration. You know,
that&#39;s usually an architecture that&#39;s
like many existing companies are
proposing. For us, it&#39;s like a a new
paradigm from the physics of the
electrons all the way up. So from the
algorithms you run on it to the compiler
to to the way the problems embedded into
the physics of electrons, right? And so
it just makes a lot of sense that as the
workloads, the typical workload you want
to run is a probabistic workload, right?
LMS are like virtual probabistic
computers that you would build a
hardware that is a proistic computer
because it&#39;s a much more natural fit. It
fits like a glove, right? And once
you once you really understand physics
and once you really understand AI
algorithms, it&#39;s like you can&#39;t unsee
how much of a perfect fit this is. And
that&#39;s where the extreme conviction
comes from that this is the most natural
way to do this algorithm. Um, and I
think I think our results are going to
show that over time. Of course, you got
to start with, you know, first
principles, some mathematics, then some
models, then some simulations, then some
early experiments, and then you scale
it, and then you show a scaled system to
people, and then they really believe cuz
then you&#39;re no longer telling your
you&#39;re showing, right? And that&#39;s the
sort of transition we&#39;re going through
this year. And that feels really good
because you know when um you know when
you have an idea that violates people&#39;s
priors right about what is possible with
today&#39;s technology um due to the free
energy principle of your brain actually
your neurons want to preserve
themselves. They&#39;re kind of greedy and
like updating your world model massively
is too costly. So your brain just
literally filters out ideas or like says
like the person proposing them is crazy.
So that&#39;s been, you know, the story of
my life for, you know, two years. I
mean, there&#39;s a lot of supporters, but
there&#39;s also a lot of of doubters and it
makes a lot of sense cuz it&#39;s like, um,
you know, overwhelming, you know, um,
this there&#39;s going to be an overwhelming
change to computing and they want
overwhelming evidence, right? But those
that can be convinced earlier are going
to get in earlier and are going to start
building for this paradigm and are going
to be ahead of the next wave. Right? And
that&#39;s like that&#39;s the history of every
paradigm shift in technology, right? And
I guess like um I exude a lot of
confidence because I thought about it
for 10 years, right? And I burned
every I burned all the boats going back
to quantum computing. I could have
worked anywhere in quantum computing.
And I I I I left that whole career and
went all in on this from first
principles conviction and now the
experiments are starting to back what
we&#39;ve been saying. Um and so it&#39;s a
really exciting time. Well, and it I
mean it is high risk because I you know
I I&#39;ve covered many many many
semiconductor startups most of whom are
like vaguely in some they&#39;re in the
ballpark, right? And and even that stuff
is risky. Anytime you&#39;re asking people
to do new software to make make big
adjustments, it&#39;s always, you know, even
when like Intel was moving away from x86
to try this new epic architecture with
the Itanium chip. I mean, there was that
was like high-risisk and and that you&#39;re
still in in vaguely traditional
computing. But there, you know, somebody
has to do something. You you can make a
easy argument for that. I just was at
Stargate yesterday, I think, and and you
know, I&#39;m looking at this like thousand
acre site is going to be pulling in more
power than San Francisco by by I think
multiple times. Um, each building I
think is $50 billion of which 60%
is the GPU cost and they want to make 10
of those buildings, right? in GPUs. Um,
I mean, it&#39;s it&#39;s like kind of amazing
that we have this video game chip that
ended up running AI, but they got lucky.
It&#39;s it&#39;s also like not hard to argue
like uh was this is not a purposebuilt
Yeah. chip for this for this job, right?
I mean, there must be a more efficient
way to do this, you would think, if you
really if you really put your head to
it. So, so like all of that makes sense.
But, okay, you guys have only been
around, I think, for two years. Two, two
and a half. And you already have I mean
we have silicon sitting on our table
like where are we at with the company?
Yeah. Yeah. So you know at first you
know we looked at the history I I&#39;ve
been following sort of physics- based
computing for 10 years right so there&#39;s
there&#39;s quantum computing there&#39;s
there&#39;s like neuromorphic there&#39;s been
attempts at probabistic computing and
there&#39;s been u uh you know everybody has
a different name for their their
paradigm. There&#39;s been many attempts,
right? And and typically there&#39;s always
a risk that they they don&#39;t kill, right?
One of them is like they don&#39;t know how
to program the device, right? So
they&#39;re, for example, neuromorphic.
They&#39;re they&#39;re obsessed with biomimicry
and they&#39;re just like, hey, we made a
neuron that it spikes like a real
neuron. It&#39;s like great, how do you
program it? It&#39;s like, well, we don&#39;t
understand the brain, how it learns, and
so we don&#39;t really know how to program
it. You got to program it. But so we had
to we had to kill that risk first. So we
she worked on how to how to program
these devices, how to map like
algorithms that have been around for 40
years, right? Statistical inference
algorithms, basian algorithms and and
and map them to to the physics of what
is called electron diffusion, right? So
so diffusion is like a generalized um
brownian motion. Everybody&#39;s maybe
familiar with brownian motion. You know,
if you drop some some flexcks of dust in
in a in some water, they&#39;re just like
diffusing around, right? It&#39;s like a
form of stochastic mechanics and
Einstein won the Nobel Prize for
diffusion is just like you not only have
programmable drift, right, of like how
much the particle moves on average, but
you program like how much noise there is
over time. Okay. And and so tell me if
I&#39;m off or not. I mean, typically
semiconductors, we&#39;re talking about
electrons being like on or off, but but
you&#39;re in this you&#39;re in this murkier.
Yeah. So it&#39;s like a cloud of electrons
and we we kind of control uh how it how
it diffuses right whether it becomes uh
sort of more spread out or it
concentrates or if it&#39;s moving on
average and by controlling that over
time we can basically create this this
programmable blob of electrons and you
know many algorithms can be phrased as
getting an an answer that&#39;s a certain
blob a probability yeah probability So
you know when you work in finance like
in finance and wall street I don&#39;t have
to explain what we&#39;re doing they all run
these algorithms called Monte Carlo
algorithms you know from Monte you know
casino uh Monte Carlo and uh you know
these algorithms were originally cooked
up during the Manhattan project to to to
do simulations of of all sorts of
systems but now they&#39;re used for
financial simulations and and and al
still all sorts of simulations of all
kinds but we can run those algorithms
basically very tightly um in all just
pieces of nature that we we add some
little control nodes and we kind of
steer it. Right. Are you steering with
electricity or Yeah. Yeah. Yeah. Yeah.
Voltages. So we have control voltages
and then by by by
uh changing the control volt voltages
over time you change the the dynamics of
this dance right. Um I think I think
what what um what is really cool about
the timing of all this right we could
have built tried to build this company
years ago but nowadays there&#39;s all sorts
of workloads like uh diffusion models
right like midjourney and I guess uh
Dolly and Chad GBT and XAI they&#39;re all
they&#39;re all using this algorithm called
diffusion denoising diffusion which is
actually using AI to go backwards
through a simulated diffusion process
right and So our algorithms that we want
to run are literally named after physics
that our our hardware runs and you know
we&#39;ve been connecting the dots over the
past few years. So so we we start with
the algorithms and we derisk that
significantly from traditional
algorithms that you know basically run
the world the financial world to modern
algorithms like genai. We connected all
the dots but then it was like okay well
can you can you create that type of
physics that that you&#39;re targeting? Can
you do so consistently? Can you control
the parameters accurately? And then can
you manufacture it at scale? So we
killed all those risks over the the past
few years. And so we started the
algorithms year one. Year two we we were
like can we even create programmable
electron diffusion cuz usually we&#39;re
using a type of physics known as
stochastic thermodynamics or out of
equilibrium thermodynamics. So this
isn&#39;t your great grandpa&#39;s
thermodynamics. This is like the core
theorems were like 1999. They&#39;re as old
as Google. for math that&#39;s really young,
right? Quantum mechanics is over a
hundred years old, right? And so for us,
it&#39;s like, can we even create like a
programmable system of this kind having
come from quantum computing, we&#39;re like,
you know, what&#39;s our breadboard
prototype? What&#39;s the most macroscopic
prototype we can create that, you know,
ensconds, right? And so so we have a
tiny chip here, I guess. What it&#39;s a
aluminum. Yeah, this one&#39;s aluminum. You
can make it out out of nobium if you
want it to run hotter there. Cool
camera. So, this one has three proistic
bits or three thermodynamic neurons.
Okay. Whatever you want to call them.
And uh they&#39;re they&#39;re macroscopic. I
mean, you could you could literally see
the features. Um am I going to mess on
it? Yeah. Yeah. No, it&#39;s fine. We have a
bunch. Uh but so that was that was our
first set of experiments in
superconductors. And for us, it was just
like a learning platform. Um, and this
has three three bits. Three
probabilistic bits. Three probabilistic
bits. P bits. Yeah. Okay. So, and then
Yeah. And then and then, you know, the
stuff we learned from that um you know,
we&#39;re going to open source like how to
create a a massive thermodynamic
computer out of out of this these
components. For us, that&#39;s not
necessarily commercially viable, right?
Because it&#39;s got to be in this big
fridge, right? You can make the fridge
smaller because it can run about 100
times hotter than a quantum computer.
Again, because we&#39;re not as sensitive.
Um but for us that that was not
necessarily practical but it was it was
to learn because we were we are the
pioneers of this paradigm like there&#39;s
no there&#39;s science has in academia
hasn&#39;t gone far enough for what we
Can I ask you a question? Like who made
the first probabilistic computer who&#39;s
tried to I mean there&#39;s there&#39;s a couple
groups, right? One of our advisers Todd
Hilton&#39;s been working on, you know, he&#39;s
the one who coined thermodynamic
computing at a university or Yeah. Yeah.
UsD and then um there&#39;s um there&#39;s UCSB.
There&#39;s Kareem Kamsar. He&#39;s working on
like magnetic tunnel junctions and he&#39;s
been working on probableistic bits for a
long time. Um, but they never figured
out how to manufacture them at scale and
use modern fab processes and and
basically you don&#39;t want to use any
esoteric components in order to
manufacture these so that you can scale
up your compute real fast and you can
manufacture it and deploy it to the
world. And that&#39;s what we figured out
with this chip. So that&#39;s got this chip
right in the middle of the board. Yeah.
Well, no, no, it&#39;s a different chip. So
this one&#39;s in silicon. So this one would
be in a ginormous fridge, dilution
fridge. You&#39;ve probably seen those like
a quantum computer and we we put out a
film like a year and a half ago on that
and everybody&#39;s like, &#34;Oh, another
computing paradigm is going to take 10
to 20 years. They&#39;re cursed.&#34; It&#39;s like,
hey, we know the problems with
superconductors. We just came from
there, right? But but for us it was like
a stepping stone. And then the stuff we
learned from there, we figured out how
to do at room temperature. So no
cooling. Originally we thought we might
need some cooling. So no cooling in
silicon. very similar physics, electron
diffusion physics. And so this chip,
what we demonstrate is that we can do
all sorts of probabistic primitives. We
have p bits, we have some other
probabistic primitives we&#39;re going to
announce uh later, but we successfully
manufactured them and we or test we
tested our manufacturing variants and we
manufactured them with one of the big
fabs and still three pits. No, this is
more like 300 300. It&#39;s 300 degrees of
freedom uh roughly. Okay. And and so You
guys say who who fabbed them? Um, we we
made some uh abroad, right? Overseas and
then we made some in America. Actually,
we did two runs. Okay. So, we can make
them in America, which is really
important, right? So, we&#39;re we&#39;re
actually insensitive to the north. In
the south or the north? America. Okay.
Okay. Yeah. But um but but you know, and
now now we&#39;re creating a much bigger
chip, right? This was a test chip.
right? Um that we&#39;re actually going to
put in the hands of of of customers and
and early adopters like this summer.
Like we&#39;re we&#39;re creating this is a test
board. It&#39;s just to like probe it and
and test it, but we&#39;re going to slap a
couple of these, put them together in a
in a cool box. Um and you you&#39;ll be able
to put on your desk, plug it in, and
program one of the first thermo
computers ever this summer. And so and I
know so this is like this alpha program
like roughly how many people might get
one of these? Yeah. I mean, the first
batch we made about 200, but we might go
up to a thousand, but then we&#39;ll we&#39;ll
probably cap it off. So, and what will
And I know you said like what I
um I&#39;m assuming I wouldn&#39;t be able to
run like a foundational model or
something, you know, on this, but but I
could run like a Monte Carlo simulation
or Yeah. Yeah. So, it&#39;s going to be like
toy versions of all all the algorithms
you could run at scale. Yeah. Right. So,
this is like a baby chip, right? But
then we&#39;re making the big brother right
now. Okay. Okay. Right. We&#39;re designing
it and and that one&#39;s going to be more
like a year from now. A year from now.
So, it&#39;s still pretty fast. That is very
fast. I mean, the it takes like what,
like two years to tape out a chip?
Normally, we we do a cadence of like
three Yeah, we do a chip every six
months. So, we&#39;re working pretty hard.
Um, is this like is this similar to
in traditional computing? Obviously,
you&#39;re trying to follow Moore&#39;s law and
you&#39;re trying to kind of get close to
doubling transistors every 18 months. In
quantum, it&#39;s been a very different sort
of cadence. I mean, so you went from
from three pits to 300 pits. Is is this
a thing where you&#39;re always trying to
add or do do you get to um like a,000
pits and you can do everything you want?
Yeah. So, already a,000 pits is pretty
hard to simulate. Um, so you know when
we when we test what we can do with the
next chip right now we simulated on GPUs
and and we&#39;re going to put out some
benchmarks of what you could do with
like a thousand pits. Well, we&#39;re aiming
for something closer to a million. Okay.
Next year. Next year. Yeah. First time
we say that. And like what happens if
you have a million pits? What can you
run on that? Yeah. Yeah. I mean there&#39;s
all sorts of generative models you can
run on that. Well, first of all, if you
if your neighbor has um a million pits
and you don&#39;t, and they operate very
fast, much faster than than running them
on GPUs, um then you can just think
faster. You could price things better.
You can estimate in certainties better.
So on a Wall Street, it&#39;s kind of a big
game changer. But for for generative AI,
it&#39;s more like it&#39;s going to look like
you hybridize, you you chop off some of
your model and you run a chunk of it on
the probabistic computer, right? But
what we what we figured out is how to
hybridize traditional deep learning
models with sort of thermal models,
right? And by hybridizing them, for
example, when you if you compare it to
diffusion models, you can use about a
100 times less forward passes or less
compute on the GPU and still get the
same performance. And then the thermmo
computes basically free in terms of
energy relative to the GPU, right? Um
it&#39;s our first system should be we say
at least a thousand times more energy
efficient. is very conservative. At a
chip level, depending how do you do the
counting, it could get to 100,000 axis
more energy efficient. So, our thesis is
that over time, people are going to
migrate more of the workload onto the
probabistic computer. But at first, it&#39;s
just going to be a hybrid. And and
that&#39;s important because you have all
these buildouts, people are putting in
$500 billion in these buildouts and then
to scale further, they need like more
nuclear reactors, which is like getting
ludicrous, right? So instead, you&#39;ll
just add some of these chips and it&#39;s
going to provide leverage to the
traditional computer co-processor type
thing. So yeah, exactly. Okay, we&#39;re
going to take one more crack at this cuz
and part of me feels like this is
impossible because I&#39;ve dealt with
quantum computing so much that I I think
even the people who work on it don&#39;t
like fully understand how it works. So
it&#39;s it&#39;s very hard to explain, but
okay. I just want traditional
semiconductor. You&#39;re creating paths for
electrons to run down and and I mean we
always talk about it like a light switch
going off. It&#39;s a very simplified thing
but you know vaguely in the in the right
direction. you&#39;re in um quantum
computing gets much harder to talk about
superp positions over paths, right? It&#39;s
different in different in different
universes you take a different path.
You can manipulate different things in
quantum like some people like quantum&#39;s
doing like a photon of light, right?
They&#39;re trying to manipulate a particle
of light and control it. You so what ex
you are still trying to manipulate an
electron, right? It&#39;s it&#39;s it&#39;s a a
bunch of electrons, right? Right. But
but we&#39;re dealing with electrons and and
but you&#39;re just you&#39;re not trying to
it from this from one state to another.
You&#39;re trying to deal more in this
murkier Yep. area and you&#39;re okay. So on
this on this like fractional bits if you
want, right? So like you know usually
it&#39;s like you have a bunch of paths your
your input can take and then depending
on the path you get a different output.
Right? And in a deterministic computer,
you have deterministic paths. It&#39;s like,
okay, I&#39;m going to go up here, down
there, up. Whereas here, it&#39;s like we&#39;re
not sure if you&#39;re going to take up or
down, but we can tune the likelihood
that you take up or down, that it&#39;s on
or off. Each transistor is on by
tweaking the charge by by by playing
with um it&#39;s not just the charge, but
it&#39;s it&#39;s just how we set it up. Uh the
control voltages. Um, but it it allows
you to, for example, uh, instead of like
a full bit flip, a full operation would
be I&#39;m always one and now I&#39;m going to
be always zero. Yeah. Right. Let&#39;s say I
wanted to go from 20% of the time um, my
my state is zero and 80% of the time
it&#39;s one, then I want to go I want to go
to 80% zero, 20% one. That&#39;s not a full
bit flip. Yeah. Right. That&#39;s a
fractional operation. But we can do
that, right? So, we&#39;re kind of like
fractionalizing deterministic computing.
Um, and and you know, you got to be more
open-minded about it, but that allows us
to, you know, just densify compute a
lot, right? And if if especially in AI
where you don&#39;t need full precision,
this is really useful, right? And so,
okay, I mean, you brought it up early in
in our chat. I mean, look, you&#39;re you&#39;re
known as the the pro tech let&#39;s go guy
and and you&#39;re optimistic and you&#39;re
excited and you&#39;re young and
enthusiastic. All all great qualities.
Obviously, there will be people who hear
you talking about going to a thousand um
a million of these bits and and and
doing this in three four years um next
year. Next year. And you know there&#39;s
semiconductors are are hard horrible
Yeah. things. Yeah. So I mean I think
there&#39;s going to be I&#39;m sure you meet
with skepticism on this. To totally no
and and I get it. Um I think you know
we&#39;re we&#39;re gung-ho. We&#39;re aggressive.
We we but we&#39;re still you know
protecting our tail risk. Like if if
something happens if the fab run doesn&#39;t
work out, we have plenty of runway to
try again, right? It&#39;s kind of like
SpaceX. It&#39;s like we&#39;re going to try to
land a rocket, right? It might take one
try, two tries, three tries. Uh for us,
the big one was like, can we can we get
the basic components derised? And it
could have taken three or four tries and
we were ready to hunker down. We got on
the first try, right? And how did we do
that? It wasn&#39;t luck, right? It was it
was really hardcore simulations in
science. Okay. How many people are at
the company? We&#39;re about 20, but I would
say like every every engineer at our
company is like definitely 100x person.
Yeah. And then is it like full of PhDs
or Yeah. So you&#39;re all you&#39;re all kind
of coming from hardcore science.
Everyone&#39;s very hardcore. Yeah. Yeah.
Either hardcore scientists uh or or
dropouts that you know are tired of
academia. Um but you usually like PhD
dropouts, right? Yeah. And you split the
engineers are split between Boston and
San Francisco or is a center of gravity.
Well, well, in a way, you know, I like
to say we&#39;re kind of an actual Manhattan
project for AI. I mean, Manhattan
Project worked on Monte Carlo algorithms
and and and physics of particles. For
us, it&#39;s like physics of bundles of
electrons and we&#39;re doing Monte Carlo
algorithms, but we we have sort of our
Los Alamos is in Boston. And then we
still need the the sort of Silicon
Valley uh DNA to go to market and like
spread this to the world. Silicon Valley
is really good at taking a technology
and spreading it, right? and and and and
creating connective tissue with the
market and then you know academia MIT
Boston you know that ecosystem is just
really good for really hardcore science
and we&#39;re legitimately doing cutting
edge science again this type of physics
is very young um usually the test beds
for this type of physics are in biology
so it&#39;s it&#39;s actually a lot of
biohysicists would get interested in
what we&#39;re doing but now we&#39;re creating
these these test beds in in silicon and
so we both have like our in-house
science for our simulations but Then we
we have our algorithmists and then we
have our our coders to to you know
create nice software frameworks to
program this. So we we need a yeah it
takes a village and uh you know right
now we&#39;ve we&#39;re we&#39;re doing some pretty
amazing things. Sometimes you only need
20 people to change the world, but you
know, I think we&#39;re going to we&#39;re going
to need to scale up quite a bit to
really, you know, bring this to the
world in a way that&#39;s uh that&#39;s, you
know, really robust and that everybody
can enjoy cuz otherwise we&#39;ll we&#39;ll get
overwhelmed with requests for all sorts
of features and stuff. So, and you there
was a wired story that came out about
you in March. Yeah, couple was it April?
I think it was April maybe. and and um
said your location in Boston is is
secret. This is this is out of out of
security concern for
the feeling like the technology so
prized you you don&#39;t want anyone spying
on what you guys are doing. It&#39;s not
paranoia. It doesn&#39;t come from par
paranoia. It comes from like yeah this
is like nation state level like this
changes global geopolitics right let&#39;s
we what we demonstrate is that you don&#39;t
need to manufacture to get the most
advanced AI processor you don&#39;t need
Taiwan right that&#39;s a big deal u people
are talking about global level conflicts
to because of that like ju just to keep
that so that&#39;s the scale the impact of
this right and so so you know we&#39;re like
Silicon you know, a bunch of tech bros
having fun, whatever. And and we have a
good attitude, but like this is this is
pretty serious stuff. Like this has some
pretty big impacts on the world. So we,
you know, we take security pretty
seriously. And in the Wired story, um I
think Will Knight wrote it. Um he&#39;s
really good journalist. The criticisms I
was kind of expecting a little more just
because hard problem. Yeah. Big claims.
What What&#39;s like the most
legitimate criticism? like what&#39;s the
biggest thing you guys are going to have
to figure out what would you say is the
most legitimate criticism against this
being possible or a good idea or
something. Yeah, totally. And and we
studied what killed every predecessor,
right? And and and you know our job as
entrepreneurs to estimate risk and and
kill it one by one the biggest risks,
right? So there&#39;s the algorithm
algorithm algorithmic risk which we
killed. There&#39;s manufacturing risk
that&#39;s killed a lot of companies. A lot
of companies they have a fancy form of
computing. They don&#39;t know how to
manufacture at scale. And that&#39;s what I
appreciate about um well, we&#39;re in the
playground offices here. Uh uh Pquantum
is like killing manufacturing risk for
for quantum computing. So I appreciate
that. But so we we killed our
manufacturing risk and now now it&#39;s kind
of like scaling and integration risk,
but you know, so far so good, you know,
in our in our simulations. And I think
um you know people don&#39;t necessarily
understand all the secret sauce that
goes into it. But um you know what&#39;s
killed quantum computing from scaling or
at least um superconducting quantum
computing is that as you scale up your
system you have noise and it gets
chaotic and you have cross talk and it&#39;s
a mess right and then and then you need
to calibrate the system and it gets
polinomially harder as your system gets
much bigger or sometimes one would say
even exponentially harder. Uh that&#39;s
like calibration and characterization of
the physics based devices like that&#39;s
that&#39;s really hard but you know Trevor
was in you know Trevor and I were in the
room where when quantum supremacy was
achieved right and you know the most
exquisite level of control we have over
nature was achieved right and and
there&#39;s a gap there between the world&#39;s
biggest supercomput and and and a
quantum system that we have exquisite
control over and all the lessons we
learned from controlling quantum systems
in a way that&#39;s like a much harder task
than this by like a lot because
everything&#39;s fuzzy here. It&#39;s actually
much more robust and anti-fragile,
right? Actually, you could even hit this
with rad Well, we still have to test
this. Obviously, it&#39;s expensive, but you
could even hit this thing with radiation
and it it&#39;s somewhat it&#39;s much more
robust than than traditional computers
because it&#39;s sort of bioinspired and
because it&#39;s if if you have learning a
system that learns in the presence of
noise, um it it basically learns to be
antifragile. doesn&#39;t um overrely on any
one circuit or or neural pathway. It
kind of builds in error correction and
fall tolerance like sort of natively.
And so so that actually makes it robust
to to manufacturing variances and and
some noise and the control and and of
course we take that into account and
that&#39;s like that&#39;s like our hardest
problem all the time. But that&#39;s that&#39;s
where the sauce is, right? That&#39;s that&#39;s
the where the real uh uh good stuff is
and that&#39;s what we work really hard on.
But uh you know I think I think the the
results are going to speak for
themselves, right? Yeah. I mean I want
to it&#39;s like you guys have made a ton of
progress. You have a very like you&#39;re
obviously brilliant. You&#39;ve got a very
convincing way. I I I read so much stuff
ahead of this but I&#39;m incapable of
asking like the really detailed you know
physics questions about about um
what I understand the challenges you&#39;ve
outlined. I&#39;ve seen plenty of
semiconductors companies get wrecked by
not being able to to manufacture this
stuff. But I mean, you&#39;re so confident
this is going to come out like in this
in this quick cadence. Um the that must
it&#39;s got to like put some people in the
industry off I suppose. Who right I mean
there must you must hear a lot people
are like oh this is going to be much
harder than he thinks. Yeah. I think I
think you need
um you know I the the way I see
innovation and sometimes I talk about
this like with with EA is like it&#39;s it&#39;s
really like we&#39;re exploring an idea
landscape and and we&#39;re kind of
diffusing and finding new modes of
thinking and you know beginner&#39;s luck
really is like having an uninformative
prior right it&#39;s like not having the
biases of the pre the establishment
industry and and we&#39;re coming in at it
we&#39;re we&#39;re coming into it from a
totally different angle
Um, but a lot of what would kill a
traditional computer doesn&#39;t affect our
paradigm. But at the same time, you
know, we do respect all the progress
that&#39;s been made in manufacturing and
semiconductors and very large scale
integration and we use as much of the
technology that&#39;s relevant for us as
possible, but then we&#39;re we&#39;re kind of
taking a fork in the road, right? But
for us, it&#39;s kind of a it&#39;s kind of a
full stack thing. It&#39;s like at the
algorithmic level, how how fall tolerant
is your your your your system going to
be? Um to me, I think I think I think
it&#39;s going to be even the future of
computing for computing in space uh
because it&#39;s going to be more radiation
resistant. But that that&#39;s a hypothesis
for now. And obviously we need to test
that. But maybe we check back in a
couple years when we have one of these
in orbit. Can I&#39;m I&#39;m the right person
for the job on that one. Um the Okay,
let&#39;s shift gears just for a second. Um
or not for more than a second. Uh so I
mean part of this where your worlds and
your identities overlap I think is that
right now we&#39;re in a situation like I
talked about with something like
Stargate where you have a handful of
companies who even have like the table
stakes to participate in AI. Um strikes
me you maybe have two countries. It
feels like the US and China are on some
kind of future that the rest of the
world is not. Um, just because of the
amount of money and the the the tech
that it takes to play in AI and create
these giant models. From all the
interviews I&#39;ve heard you ever do, it
sounds to me like you have you think
well you talk about AI needing to be
democratized. I think the spirit of that
seems to be that you think if we&#39;re
creating this super powerful technology,
everybody should have some kind of
access to it, right? Otherwise, you&#39;re
just even if you have a benevolent
overlord, you have a overlord, right?
And and and and you can&#39;t touch it. And
you this is where the overlap happens. I
mean, you think you think this this is
the path, right, to to making that
possible. That&#39;s right. Right now it&#39;s
kind of like there there&#39;s a power of
symmetry right now with like if you if
you need a big supercomput to run an AI
you can&#39;t have like a personal AI
supercomputer right maybe they&#39;ll
reserve a few racks you know fraction of
the time for you but really it&#39;s not you
don&#39;t own your own weights you don&#39;t own
the extension into your cognition and
right now we don&#39;t even have like that
many personalized models it&#39;s like one
big blob and we&#39;re kind of like we&#39;re
slowly kind deferring our cognition to
it and in a way we&#39;re converging to like
a Borgl like mind, right? Like if we&#39;re
all like we we all share one common
extension to or cognition where like
it&#39;s no we we&#39;re kind of losing our
individuality and and I think like
individuality is it&#39;s fundamentally
important. Um I think you know I view um
the the search over the space of
technologies and innovation and progress
as yeah as as sort of it&#39;s an explore
exploit problem but to explore the
landscape you need different you know
groups of people exploring different
things to find new ways of doing things
and if you if if we converge onto a
handful of tech companies that you know
technically they all train employees
between them we&#39;re kind of stuck in in
one way of thinking in one cluster and
there&#39;s the risk that there&#39;s a totally
better way of doing things and we&#39;re
totally missing out on it. And if we
kind of crown winners too too early and
say actually, you know, only only they
are responsible enough to run AI at all
and nobody else should have access to
AI, that&#39;s just really bad for progress
overall. And like you said, it it it
creates this sort of risk of of tyranny,
right? Like even though right now you
might trust whoever is in power,
eventually if you overconentrate power,
it becomes a target to the power
seeking. And then you know from a you
know designing our civilizational system
to be fault tolerant right like I view
everything as having probability of
having some noise some dropout or some
replacement like if you if you have a
set of nodes that are too powerful
you&#39;re too sensitive to corruption of
those nodes right so the answer is to
decentralize and diffuse AI power in
order to do that you need a
densification of intelligence you need
densification of compute you need to be
able to have a computer at your desk or
in your home that that is an extension
your cognition that provides more value
than a big centralized model that runs
on a supercomput. How do we get there?
Well, we need, you know, compute that&#39;s
a,000 10,000x more energy efficient.
Trying to get it even further than that,
right? Our brain&#39;s about 100 million
times more energy efficient. Depending
on the algorithm, we might get close to
that uh with with this paradigm as as it
gets better. Um, again, because we&#39;re
using the same kind of physics, but
instead of neurotransmitters, it&#39;s it&#39;s
electrons. I mean, to me, you know,
there&#39;s been all sorts of push back.
Obviously, it&#39;s polit politically high
stakes um topic, right? There&#39;s like the
companies trying to achieve regulatory
capture and then there&#39;s like little
tech and startups. They want they want
like a even playing field so they can
play ball. Uh but you know in in general
we win from everybody being able to
compete and everybody being able to
compute to AI research and progress and
also just from a sort of individual
sovereignty level like you want to own
the extension of your cognition. It&#39;s
yourself, right? Like, and you want to
control it. You want to be able to
control what it thinks. It&#39;s its own
like subculture. You want to you want to
be able to be an individual. I think
that&#39;s really important. Otherwise,
we&#39;re all going to kind of be squashed
into like have like if if a set of
companies control the extension of your
brain and it&#39;s like the collective
extension of our brain, then they could
just like steer it to think a certain
way and and now they kind of control you
by proxy. And and to me I think that&#39;s
like that&#39;s fundamentally risky. And so
we kind of have to to arm the rebels,
right? Which is you know everyone else.
And I think um you know that that&#39;s my
goal with this this paradigm of
computing. You know, I think in a in a
previous era, this would have been like
a crazy, you know, Manhattan-like
project of the government, but we&#39;re a
Silicon Valley company, right? Like, and
and it&#39;s funny cuz like I really wanted
to do this my whole life and, you know,
I looked at academia didn&#39;t seem like
the place to do it. I looked at like big
tech, eh, you know, and then and then I
was an entrepreneur in big tech, like a
special unit division. Even there, too
much paperwork and too much red tape.
National Labs. I had friends there.
Didn&#39;t seem like the way. So startups
are the only way to pioneer this stuff.
And so people have skepticism because,
you know, venture capital backs all
sorts of plays. Some of them more
serious, some of them less serious, but
we&#39;re on the much more serious spectrum.
But, you know, our science is very
serious, but we&#39;re we&#39;re having fun with
it, too. we&#39;re we&#39;re you know I&#39;m I&#39;m
kind of a jester online and and I think
that that maybe like disarms some people
or like that&#39;s that&#39;s like I don&#39;t fit
their priors of like serious scientist
and lab coat but you know I I and I I
think like people have have biases
against that in general and but I I I
play those biases against them right I
think I think what people don&#39;t realize
it&#39;s like you know with with EA as well
you know it&#39;s like um you know AI safety
we&#39;re very wellunded organization and
and they were having all sorts of
political influence, right? And then,
you know, I start as an anonymous
account named something ridiculous with
like a over-the-top avatar named Bev
Jesus, right? It&#39;s like, why why would I
do that? Well, it&#39;s it&#39;s sort of
disarming cuz then the very holier than
thou, very serious AI safety has to
debate an anonymous cartoon figure on
the internet, right? And they&#39;re already
like, you know, and and so it&#39;s like
it&#39;s disarming them of their their sort
of holier than thou attitude. And so I
think you know I like to I mean this is
kind of revealing my trick but like I
like to be like on the edge. I think in
modern sort of um not just marketing but
just getting attention. Attention is
important to get the right talent, right
human capital and capital. I think being
at the edge of like being surreal but
being like metaonic like it&#39;s like you
don&#39;t know if I&#39;m serious but I&#39;m
actually serious, right? I think that&#39;s
kind of optimal because then people
debate it. Um, people debate their
beliefs and if they&#39;re debating the
beliefs, it gets more engagement. It
gets more amplification. And for us,
honestly, like this whole this doxing is
unfortunate. It like it it&#39;s definitely
changed my life for better or for worse.
There&#39;s definitely some a lot of
negative aspects, but to me, it&#39;s like
um it&#39;s been useful in like finding the
six sigma talent out there, right? if
you get a billion views in a year, um
you can basically find the several 1 and
10 million engineers, right? And and
then you could collect them and then you
could do a really hard project. And
that&#39;s that&#39;s what people don&#39;t
understand. That&#39;s how Elon works as
well. He gets the very best engineers
cuz everybody has heard of him. And it&#39;s
kind of a you know in EK I talk about
you know techno capital uh human mimetic
machine but and it&#39;s all co-evolving but
in a way like culture and memes are
upstream of the flow of capital and
human capital right and so capturing the
mimetic sphere was like an instrumental
goal to to to to get people to learn
about this because um another thing is
like you could create the technology in
a lab Right. But if it&#39;s nobody hears
about it, pick it up. Nobody nobody
picks it up. It doesn&#39;t get enough
funding to actually have the activation
energy to scale to the world. And then
we&#39;re kind of slowing things down
artificially. And you know, one of our
goals with this is like simulating
biology in a way that&#39;s, you know,
100,000 times eventually a millionfold
better than the way we do it today just
because it&#39;s a much more natural fit uh
to simulate biology on this computer and
that could save a lot of lives. So, I&#39;m
just doing the calculus like what would
you do if like you could save a billion
future lives by going faster, right? And
and and and to me, it&#39;s like if we if we
secure sort of the public awareness and
the distribution
uh uh and it&#39;s ready for when this this
tech is ready and we&#39;re going as fast as
possible with the tech, then it&#39;s going
to have the fastest uptake and then
we&#39;re going to we&#39;re going to raise
everybody everybody&#39;s prosperity and
wellbeing up much faster, right? And
that that&#39;s basically the core argument
of EOK is like there&#39;s an opportunity
cost to slowing down and and and and
often it&#39;s not in the discussions of of
risk mitigation, right? And you know
there&#39;s you can either focus on downside
protection or focus on the opposite
which is like not missing out on on huge
upside. And the thing about upside is
that it compounds exponentially. So the
more you wait, the more the opportune
cost is, right? And and so I think I
wanted to bring balance sort of the
debate in in Silicon Valley because it
was leaning towards like tech doomerism,
right? Not just for AI but for
everything. So no, I okay, as I was
preparing for this, it was just
reminding me of a lot of things. I I
don&#39;t think I will want to debate you
about the doxing thing, but I will. But
that&#39;s not actually what I&#39;m most
interested in. Um the um you know I what
I when I first started out as a reporter
I mean it&#39;s like the open source you
know I was this young kid
I wasn&#39;t really into tech that much and
I&#39;m I&#39;m like going in to cover
semiconductors and servers. There wasn&#39;t
a lot of like romanticism in it but as I
you know I started to get into the
engineering to learn it and that was
cool. What I really got into was the
open- source movement because I was like
young and idealistic and I, you know,
Microsoft was being held up as this
enemy, these these these proprietary,
you know, capitalist and on the other
side were the people that wanted to
share um all this knowledge and
information and and and I I embraced
that and like identified with it or
yeah, I don&#39;t I just got into it and and
the um it&#39;s interesting to me like what
So this is like or early 2000s. I mean,
you&#39;re too young and maybe lots of
people in this field are. This was like
a major religious war. It was like the
world could choose two paths, you know,
and and one was like felt like
righteousness and and truth and the
other one felt like it&#39;s just like we&#39;re
going to chase money and make, you know,
whatever products. And it&#39;s weird how
this has played out because both sides
have kind of one, but it, you know, open
source is massive. It&#39;s everywhere, but
it doesn&#39;t carry with it still this like
man. I mean, I remember like the free
software movement. This was this was
like serious stuff that got debated in
in like major circles. I feel like what
you have been articulating is reminding
me of
um some of the spirit of all that,
right, which is like people get
into it&#39;s like Facebook&#39;s putting out
open source models and it&#39;s they get
some pats on the back. I I hear like
little rumblings of people who are like
cheering for open source, but it&#39;s
definitely not the same level that it
used to be. And then otherwise, we&#39;re
not even having this debate about who
controls this massively um powerful
important technology. So, I give you I
actually give you like major credit for
not only um charging after this, but
being very like
articulate around how you put it. And I
I think it is weird to me like the the
dominant intellectual religion that
would have been the open- source
equivalent really was effective
altruism. Well, at least a branch of EA,
the the kind of AI focused end of it.
Um, well, ironically, they want to, you
know, it morphed into the AI sort of
doomer movement and then they&#39;re
alarmist and then they actually want to
close things down as much as possible.
Yes. Control. That&#39;s what I mean. Like
open source was a different thing,
right? It was like you get more control.
It wasn&#39;t trying to stop anything or
slow anything down. It was like who who
has the who has the power? Do the people
have the power or do the companies have
the power? That&#39;s what we fought for
with EA, right? Right. Cuz because
really EAC is not necessarily about just
decentralization or or centralization.
It&#39;s about hey, we got to do whatever is
best for the growth of the system.
That&#39;s what naturally ends up happening.
But right now, if we overconentrate
power, that&#39;s just bad. That&#39;s bad for
speed of progress, right? Because you&#39;re
not innovating as much. And it it&#39;s bad
for for fall tolerance and and you know
like risk of tyranny, right? If you have
um if you have a gap in intelligence,
right? If you have a system that can
predict another system uh really well,
then it can control it, right? And and
you don&#39;t want a power asymmetry, right?
It&#39;s and and and now this gets into, you
know, this is more controversial, but
like parallels to the second amendment,
right? If you only have only the
government has a monopoly on violence or
weapons and so on and then the
individuals can&#39;t defend themselves then
then you end up with sometimes a tyran
tyrannical government right but if if
there&#39;s a sort of backs stop that
individuals have maybe not as powerful
but like together they could band
together and be a powerful force if they
if if you sort of equilibriate power a
bit more between top and bottom then
then then you have a nice you know game
theoretic equilibrium right and so to me
I want to diffuse use the power of
artificial intelligence to individuals
and smaller organizations because that&#39;s
not just the big centralized
organizations that have a monopoly over
it. And and that gets me into I guess
like more recently like I guess the past
two two and a half years we&#39;ve been like
just fighting on the regulatory front
like to to to stop all these like
regulatory capture bills or trying to
like use AI panic to to slow things
down. We think it would be really bad
for everyone. I think I think the debate
now um that&#39;s like really front and
center in politics and that&#39;s related to
this is sort of you know how how do you
view China right like to to me like
China has um you know they have a set of
executives that kind of control all
these companies they&#39;re kind of a a big
umbrella corp right like they they
they&#39;re kind of like one uh uh
conglomerate in a way and they use their
sort of meta monopoly power to to crush
any American company that tries to
compete with it Right. And and you know
in the spirit of EA of like fighting
over fighting against over
centralization right now it&#39;s like hey
it seems like we need to like create
some competitors to all these these
Chinese suppliers so that we we have a a
hedge against like them trying to abuse
their power right and you know for
better for worse the current admin&#39;s
trying to do stuff you know whether
they&#39;re doing the right stuff and stuff
for for debate but like I think the the
thesis of what you know needs to happen
is is roughly correct and I I you know
I&#39;ve and lending my hand to to that in
in some way. Again, I&#39;m I&#39;m more of a
Does that make you anti-Canadian to I
don&#39;t know about that. I&#39;m more I&#39;m more
of a centrist libertarian, right? And
there&#39;s there&#39;s no third party and so,
you know, I think um you I think I think
Elon&#39;s very aligned with with our our
framework, even though sometimes he and
I kind of uh debate where like I&#39;m more
optimistic about the future of of AI and
how how it&#39;s actually going to help us.
Um, it&#39;s not just like because right now
we&#39;re in a paradigm of like we create we
train these AI model parameters and and
we give it a lot of compute, we give it
a lot of resources, but it&#39;s actually
eventually going to take care of us in
in a way like we&#39;re going to be able to
simulate our biology, fix a lot of
diseases, um, improve ourselves and and
and and essentially, you know, it&#39;s sort
of a soft merge in a way, right? Like if
you have an iPhone and you have a a
neural link and uh you know it detects
whatever is going on in your body
creates a custom peptide injects it like
you could just we become like this this
sort of cybernetic system and and to me
that&#39;s sort of the vision of the future
you know I want I think like um I I
think both the biological substrate I&#39;ve
I&#39;ve actually gained a lot of respect
for it trying to reverse engineer it uh
I think we underestimate how much
compute goes into our bodies and how how
much it would take to simulate it. It&#39;s
actually much harder to simulate a cell
than than like a human brain, I would
say, or like at a at a coarse grain
level to get the same sort of output,
which is what AGI is trying to do. I
don&#39;t like the term AGI. Um, we can get
into that. Uh, but uh it&#39;s it&#39;s more
like human like AI or anthropomorphic
AI. I think there&#39;s other forms of
intelligence that are nonhumanike that
is present in nature that we can tap
into. I say or biology and really any
sort of complex self-organizing out of
equilibrium the dynamic system is a form
of intelligence right um and that&#39;s the
sort of intelligence we&#39;re tapping into
um but um yes I lost my train of thought
no this was I think we&#39;re we were just
we&#39;re getting into the the AI juice the
totally random sorry go for it the why
did you pick
Jeff Bezos instead of Elon I mean Jeff
like But yeah,
Jeff does cool things, but doesn&#39;t carry
the same kind of uh tech
accelerationism, I think, as as Elon
might. I think I think I think Jeff I
think Jeff&#39;s pretty eek I think he
actually followed me before Elon on the
account. Yeah. Um but I think
originally, you know, I was I created
the account. I was working at Alphabet
and I worked for for Sergey and you know
I read that were weren&#39;t you like were
you like Sergey&#39;s right-hand it was a
unit working for him directly and you
know he&#39;s really into physics. Uh he&#39;s
really brilliant and he was really into
quantum physics and having his the whole
thesis was to have uh physicists come in
and then learn either quantum computing
or AI and and be kind of like first
principles thinkers for for these
subfields, right? And that&#39;s kind of the
unit uh we started. And uh you know he
he&#39;d basically have physicists around
him. Um and trying to trying to be a
look ahead a sort of special projects
division. And so for me it was like okay
well that&#39;s perfect misdirection. Maybe
people will think I was working on
Amazon or something. And so um but you
know I had the account and then I
basically started yak when I was when I
when I left and I was starting shopping
basically. Yeah. was um because the last
so Sergey was into quantum and now he&#39;s
he&#39;s kind of doing AI. Well, he has to
all the time. It&#39;s existential now
because for for Google and for for
human how when you say that existential
for him how do you think well I mean
it&#39;s you know for the business model
right like I think Google was always
intended to be a thing that gathers and
organizes the words the world&#39;s data and
and and to do that to make data useful
it&#39;s basically an AGI company since the
beginning right I mean if it weren&#39;t for
Google I don&#39;t think this whole AGI era
would even work right like the the fact
that they help you know be the
connective of tissue or the interconnect
for the web just made the web what it is
and then that created this sort of petri
dish with the data nutrients we needed
to to grow these AIs right now we&#39;re
doing all these experiments like if you
feed it data and you you grad it it
works like magic right but it&#39;s like
without the data we wouldn&#39;t be here and
without the compute either so well I
mean there&#39;s a weird path where like the
second the transistor was created it
feels like tech has been carrying us on
it&#39;s like first we&#39;ll help you make
these computers and then we&#39;ll create
this network and you&#39;ll feed it with all
these words and all your thoughts and
you know and then we&#39;ll that&#39;s what we
will need for our food for this. That&#39;s
um that&#39;s really interesting cuz like um
sometimes it looks like it&#39;s sometimes
it looks like self-organizing systems
are assembling themselves from the
future, right? Um but really if you just
look at at the equations, it&#39;s just like
um the likelihood of a trajectory or set
of events happening is exponentially
more likely if it um gathered more
resources and and use them up for
further growth. So it&#39;s it&#39;s it decays
exponentially uh depending on how much
free energy you&#39;ve consumed. So what
does that mean? It just means that
looking backwards, it&#39;s going to look
like we&#39;re always like on the optimal
trajectory for growth. But that&#39;s just
always what self-organizing systems do.
And if sometimes you you just
intuitively feel like a technology is
high utility and you and it&#39;s like or or
a thought or like um if if something
feels instrumentally useful intuitively,
we kind of are hardwired to like
understand that it has a lot of
potential upside later. So then looking
backwards, it looks like, oh, we did all
the right things to get to this point,
but but really it&#39;s just kind of um
yeah, it&#39;s just intelligence, right?
Intelligence is like our ability to to
predict the future and and to to
maximize our our expected reward in the
future. And if the reward is is is
growth and prosperity and resources,
then then it&#39;s going to look like we
took a path that was pretty pretty
optimized. But there&#39;s no there&#39;s no
like backwards in time sort of
communication. But sometimes we we we
joke about that in our marketing just
because it looks like that. But it&#39;s
actually really interesting how um these
this sort of like this this this process
of organ organization which emerges from
just the fusion of a bunch of variables.
It&#39;s really much how our hard hardware
works. It&#39;s a process going forwards but
it it can replace the need for back
propagation. Right? So if you so even
though we&#39;re just running a process
forward of diffusion optimization it
almost looks like there&#39;s information
back propagating through time that like
we&#39;re trying to reach this
optimum and and guide ourselves there
and and we use that fact to to train
models without uh backrop on on these
devices and any total technical tangent.
No, no. And then like I
mean I vaguely related, you know, I&#39;ve
heard you talk about um Okay, you just
talked about you would like a future
where we have this this merge. I think
you called it a light merge, some kind
of merge
um between flesh and machine. And then
I&#39;ve heard you talk about you went
through this kind of like ego death
where humans and life fits into the the
universe that that you know some of the
laws of the universe appear to be this
desire among successful things. this
everex expanding chase of energy and
growth and and um like my sense was okay
my sense was like you sort of see a
future where humans when you talked
about this is how I interpreted when you
talked about ego death was maybe our
purpose is just to to help build this AI
and then have it marching off through
the universe to to um expand and explore
and grow and and chase energy and that
that that was our job. Um, is that is
like like if you&#39;re if you&#39;re an
accelerationist, you&#39;re protect like
what&#39;s your end goal for all this? Yeah,
I think I think that&#39;s like the the old
view, right, of like I think I think
Larry was the one who thought we were
like, you know, Larry Page. Yeah. Yeah.
Larry Page is the one that that, you
know, argued with Elon that we&#39;re just a
biological bootloader. Again, we&#39;re
doing bioinspired compute. Um, I think I
think I think the next uh frontier
that&#39;s maybe taboo is is really viewing
biology similar to sort of um software
2.0, right? Software 2.0 is deep
learning models. We have parameters, we
have prompts, right? You could think of
like, I don&#39;t know, peptides as as
prompts for your system, right? And then
you could think of your parameters as
your your genes, right? And I think I
think we&#39;re going to start hacking both.
And there&#39;s no reason we can&#39;t have as
fast progress on the biological
substrate as the silicon substrate.
Right. Yeah. We can go together. Well,
so but the the point is that if we don&#39;t
like things that don&#39;t accelerate,
things that are constantly evolving and
and trying to adapt to optimize
themselves towards growth, they tend to
to fade, right? And so we actually, it&#39;s
not like, oh, the future is doomed or
we&#39;re set. It&#39;s like, no, we got to like
actively keep working on it. Like, we
actually need to accelerate biotech
research. We need to deregulate it. We
need to be more open-minded about it. I
think this is the next frontier. I know
I know like the debate right now in
America has been about like
semiconductors and AI, but I think
biotech&#39;s the next big frontier and and
China is just like plowing right ahead.
And then they&#39;re again they&#39;re same
story again. They&#39;re just trying to
monopolize the supply chain for for
drugs and biotech. And I I think you
know I&#39; I&#39;ve also supported why are they
so much smarter than we are? I think
they just think on a 50 to 100 year time
scale and we think on a two to four year
time scale right and um you know but but
as a as a entrepreneur if you&#39;re doing a
take you know a company for like 20 30
years then you&#39;re already you already
have more of a stake in in the in the
future more than let&#39;s say a politician
that sticks around for just a couple
years right so you know I&#39;m I&#39;m trying
to like understand the world on a 20 to
30 to four year time scale cuz That&#39;s
that&#39;s the length of my play time, if
you will. Probably as CEO, who who
knows, right? Hopefully. Um and uh and
so I&#39;m I&#39;m trying to have a model of how
it&#39;s all going to evolve and and skate
to where the puck is going, as we say in
Canada. Um and so um but but you know, I
I I&#39;ve going back to biology, you know,
I&#39;ve I&#39;ve lended a hand to like this
fork called like the bioact movement,
which is like for freedom of like
biotech progress and exploring like
brain machine interfaces and so on. But
uh to me I think all substrates are
going to accelerate. There&#39;s going to be
like pure biotech accelerationism. You
know Brian Johnson in a way is like one
of the the people pushing the boundaries
there. friend of mine and then there&#39;s
going to be like the merge the middle
ground right like so Neurolink science
like our friend yeah friend Max Sodak
and then um and then there&#39;s going to be
pure silicon but like all three are
going to co-evolve right it&#39;s like is it
going to be this this or this like yes
all the above right everything&#39;s going
to try to accelerate as fast as possible
and so I think people have said like I&#39;m
open-minded like substrate agnostic
right and then they take that word it&#39;s
like oh he&#39;s anti-human it&#39;s like no no
I just think like just fundamentally
like these equations of thermodynamic
evolution, right? Or or the
thermodynamic selection, right? That
every bit of information specifying
configuration of matter is being
selected for its ability to confer
growth. It&#39;s like there&#39;s a fitness to
every bit. So every culture, every
aesthetic, every policy, every
technology,
um it&#39;s substrate agnostic, right? It it
doesn&#39;t care. It&#39;s just it&#39;s just
physics, right? And we&#39;re just like in a
big petri dish that is our civilization.
That&#39;s a self- adaptive system and it&#39;s
reconfiguring itself for growth. And
that&#39;s just the reality of it, right?
And people get screaming at me. It&#39;s
like that&#39;s just it&#39;s not an
anthropocentric view, right, of of the
world, right? And there&#39;s a push back
just like saying the earth is not the
center of the universe. That offended
some people back then. It&#39;s like human
intelligence is not the center of the
universe. Humans aren&#39;t the center of
the biological design space or and and
and even like biological substrate isn&#39;t
like the the the center of the design
space of self assembling or
self-organizing intelligence systems,
right? And so it&#39;s not cuz we&#39;re not in
the center that we should just give up.
I think I think we should just keep
everything going and actually accelerate
and and just keep an open mind about the
future. Have you been like this forever?
Were you like this as a kid? Were you
like I mean you&#39;re this weird mix of
like philosophy and and like hardcore
tech like on a Yeah. on a proper
science. I never fit in any one bin. Um
so you know what did your parents do? Uh
doctor and
engineer/ontrepreneur. So um but growing
up like I was always on a mission when I
was like 7 years old. I was like reading
Stephen Hawking and I want to I want to
figure out how to create the most potent
technologies to advance civilization and
and and reach the stars. So originally I
want to be a theoretical physicist to
figure out interstellar travel. But like
since you were a kid. Yeah. Since 7
years old I was talking about subatomic
particles, how I want to be an
astrophysicist, figure out this
technology. Like everybody be like this
kid&#39;s weird. He&#39;s like, you know, an
alien sent from the future trying to
figure out how to assemble the most
potent technologies and and scale them
to the world. But it&#39;s it&#39;s really I
just been mission driven since I was a
kid and there&#39;s a lot of people that
have known me a long time that can
attest to that. So, were you one like
were you one of
the aced all your classes or were you
more I was more of a generalist, right?
I think like you know I skip a lot of
classes. is I&#39;d just learn it learn
maybe faster in my own pace and
sometimes I&#39;d be bored in classes. I
played football growing up. I played a
lot of sports. I went to sports school.
Canadian. Canadian football. Yeah.
Canadian. Well, Canadian football. It&#39;s
pretty close to America. Canadian high
school. Football is pretty close to
America. I have friends in the NFL who
were also doctors and stuff. Um yeah, I
don&#39;t know. I did some theater. I did I
was just like I don&#39;t know kind of a
generalist. And I feel like um you know
you don&#39;t you don&#39;t want to over
specialize too early. You want a kind of
broad data set. And I I think um you
know I think growing up playing sports
is like gave me a sort of physical
intuition and physical intelligence and
that&#39;s actually been really useful to
like all the algorithms I design usually
I I try to picture in 3D phase space and
and then transduce like the picture out
of my mind to to to math and then
algorithms and then code and then
product, right? And that&#39;s sort of the
pipeline. Um and uh I think I I think
people tend to want to oversp
specialcialize maybe too early. Um, and
there there&#39;s a book on this like range
and stuff. It&#39;s called like you you
don&#39;t want to be like Tiger Woods. You
don&#39;t want to over specialize too early.
Then you reach a sort of local optimum,
right? And so I think my big strength
has always been to to just never stay in
my lane. Yeah. Right. And you know, I
was in theoretical physics and then I
was telling my friends like, &#34;Hey, I&#39;m
going to go to Google and build like
quantum machine learning and and lead
the product there.&#34; And they&#39;re like,
&#34;You really?&#34; And then I was in quantum
and everybody&#39;s like, &#34;Okay, this is the
quantum guy. This is the bin he&#39;s in.
Yeah, I&#39;m going to leave and I&#39;m going
to do hardware. I&#39;m going to do the
whole stack now. Oh, that&#39;s crazy. So,
they&#39;re always going to call you crazy
when you don&#39;t stay in your lane. But
you kind of have to do it cuz then
that&#39;s how you get this sort of synergy
between fields and you find new ways of
doing things that you know people that
are over specialized would have never
guessed cuz they&#39;re too close-minded.
So, I should know this. I&#39;m sure I did.
Were you like in a PhD program when
Google pitched? Yeah. Yeah. Okay. So,
you you&#39;d gone deep. You must have done
some run through philosophy at some Oh,
uh yeah. So, in Canada, we have this
thing. It&#39;s like it&#39;s like uh senior
year and freshman year. It&#39;s called
CJP. Uh it&#39;s um yeah, I did philosophy
back then. Okay. Did any philosopher in
particular call to you? Um I mean, I
think we had a course on like
rationalism and so on. I thought that
was that was really interesting. But I I
think to me really like um the ego
there, you know, there&#39;s a couple ego
deaths basically throughout my career.
One of them was, you know, I wanted to
be a theoretical physicist originally. I
wanted to figure out a theory of
everything and they&#39;re uh you you&#39;re
trying to reduce the universe to a few a
model with a few parameters. It&#39;s very
simple, right? So it&#39;s a reductionist
approach. It&#39;s like I write one equation
and then that&#39;s the whole thing, right?
And I think over time that that I think
that program has failed. It&#39;s just it&#39;s
it&#39;s like physics has stalled and now
it&#39;s more like complexism that&#39;s kind of
winning. It&#39;s like actually even maybe
spacetime and and most interesting
systems have like emergent properties
that you can&#39;t get around the
computation it takes to to mimic that
emergence, right? And that&#39;s Steven
Wolram&#39;s theory of irreducibility, but
we were seeing that to some extent. you
know, I was studying quantum condensed
matter and and and the intersection
between uh models we use to model exotic
matter and and like even like emergent
spacetime from from quantum degrees of
freedom. And it it just seemed like,
okay, actually to understand the
universe, we&#39;re going to need way better
computers and then those computers are
going to run better simulations. And
then if we&#39;re trying to get a TLDDR
reduced model that&#39;s fewer parameters
then we use AI which basically
compresses complex dynamics to a few
parameters and gives us predict
predictive power. That&#39;s the goal of
science, right? It&#39;s just to have a
model of the world so we can use it to
do stuff, right? Uh and so I saw like,
okay, well, I got to push AI all the
way, right? And then started off, you
know, the natural branch was to go to
quantum computing and pioneer quantum AI
because that was the type of AI that was
going to allow us to understand quantum
mechanical systems and maybe even
quantum gravity, right? And and that&#39;s
that was kind of the the natural first
step. So pioneered that sub field, but
then over time I was like actually we&#39;re
missing a whole big piece here. You
know, the the meat of the sandwich was
like the messoscales, right? It&#39;s like
um you know, everything between quantum
and cosmos is like more or less the mess
scales. The laws of stoastic
thermodynamics apply. And so I wanted to
focus on an AI system that would be the
ultimate substrate to understand those
scales. And you know, I paid my dues on
the quantum computing side. Again, I
think I&#39;m still rooting for quantum
computing. I still think we&#39;re all going
to like it&#39;s going to be a merge of all
those types of computing together to be
able to understand all scales of the of
the universe and learn a master
representation that can basically learn
a compression code of anything in the
universe. That&#39;s the goal to me. That&#39;s
real AGI like that you can actually
ingest any data quantum mechanical
messoscale
molecular actually have a predictive
model of a chunk of the world and maybe
even inverse design pieces of the world
right like I want this material that has
this property that&#39;s the final modality
is matter um yeah I think to me to me
that&#39;s that&#39;s the goal of where we&#39;re
going to and I think I think the human
like or human level intellect is just
like a milestone on this journey And we
shouldn&#39;t be too self-important about
it. I think saying like as soon as AI is
smarter than me, then it takes over the
universe. It&#39;s like it&#39;s very, you know,
self- aggraizing even though, you know,
I&#39;m larger than life. It&#39;s funny coming
from me, but like I don&#39;t know that
that&#39;s just been my point in a way like
I&#39;ve been humbled by how powerful nature
is and and how much actual inherent
computational power there is in nature
because you know I&#39;ve been trying to
mimic it and and and capture it but also
harness it. Um and really it&#39;s like my
whole career and journey has been like
bringing nature inspired computing to
the world, right? And so from quantum
and nature inspired intelligence to
quantum now thermo and I think uh you
know I think this is the mission um it&#39;s
the most important thing I could be
working on because having more
intelligence per watt with you know
thermodynamic computing and then pushing
the culture to push civilization towards
having more watts per civilization. You
multiply those two we increase the total
amount of intelligence we have in our
corner of the universe. And to me, we&#39;re
like a very special state of matter
that&#39;s precious in the universe. We&#39;re
pretty rare, so it&#39;s worth preserving.
And in order to preserve it, we actually
need to keep growing or we slowly die.
And that&#39;s what the physics of life
tells us. And um that&#39;s why, you know,
that&#39;s been uh my mission with kind of
these two identities uh coming together.
So that seems like a good spot to stop.
Unlike some of the other podcasts you&#39;ve
been on, I do not go for for 19 hours
and and endurance test you. Um that was
that was like a a lovely um I think we
just took a little trip through your
mind. That was good. Um I&#39;m going to do
like just super quick rapid fire. Yeah,
let&#39;s do it. Question round. Some of
them possibly stupid. Um if you this and
this is rapid fire holding you to that.
Um, if you had to pick a quantum
computing company that you think makes
it to the other side, which one do you
pick? Either um I would say Sciquantum
or um Qera. I think those are my top
picks. Okay. If you look at
the five, four, five major AI, you know,
the ones the with the foundational
models at the head of this thing. I
don&#39;t know. Each one of them you could
argue is a cult of personality. Um I
know you&#39;re fighting against the grain.
Does does any one of the cults, you
know, like vaguely appeal to you more
than the other? Um you know, I&#39;m I&#39;m I&#39;m
good friends with people from from all
all the cults. Uh I you know I think
opening eye and XJI I have the most
affinity to and I think anthropic
they&#39;re they kind of like culturally are
are focused on kind of the safetiest
camp even though uh you know it&#39;s funny
I knew some of the founders of Enthropic
or one of the founders in theoretical
physics before um but you know I
obviously cheer on like the open source
uh uh players you know like uh like
Mistral and Meta. I think it&#39;s really
important to have open source. I think
uh I think you need both like you said
right like you need you need the the the
big labs that that capture some of the
value but then reinvest it you know into
training bigger models and kind of
setting the pace and then you&#39;ll have
open source that kind of diffuses the
power and creates like a lower bound for
everyone so there&#39;s not too much of a
gap between the the halves and have
knots of access to private models and so
um yeah I I would say um you know I I
think um I think I think opening I
changed a lot culturally actually over
the past couple years especially after
after the shakeup. Uh I think shakeup
that&#39;s that&#39;s an understatement right
but but you know um we&#39;ll see how
Mirror&#39;s Lab you know orients themselves
on on the spectrum of of sort of um
safety as to to to full boore
acceleration. You know to be fair to to
to Open AI they&#39;re they&#39;ve been pretty
they&#39;ve been accelerating quite a bit.
they&#39;re not holding back much. They&#39;re
setting the pace for everyone else and
and then XAI is like really close up
there, really trying to give them a run
for the money and then and then that
keeps them, you know, pushing further.
So, I think that&#39;s good. And that&#39;s
basically was the fundamental thesis a
year a few years ago. It&#39;s like if you
only have one player, they&#39;re going to
become complacent. They&#39;re just going to
like focus on reg on capturing the
market rather than like innovating.
Whereas, if you have open competition,
everybody has to accelerate or lose.
Yeah. Right. And and here we are and
everybody benefits because we get these
these amazing models for like pretty
cheap. Like paying like 50 bucks a month
sounds like a lot, but like you have a
PhD level like analysts that you could
just like type to. It&#39;s crazy. It&#39;s
great. So
is Eleazar actually a greater
accelerationist than you are? How so?
How would that be? My theory is that
he&#39;s scared if Okay. You go back to like
Google, deep mind. Yeah. AI is kind of
contained in one spot.
He freaks everybody out. In particular,
Elon, causes them to form. Open AI, sets
the whole arms race in motion. I I think
he actually like completely undermined
everything he was trying to do and
created the arms race. He was the best
salesman, right? like fear-based uh
marketing. So, he&#39;s the best salesman
for it. Possibly beat Bef Jesus. Yeah.
Yeah. Maybe. I mean, kudos to him,
right? Like, thanks to him. Uh, you
know, we are here now. Um, I think I&#39;d
be building this even if the current I
mean that we started this company before
Chad GPT, right? Like I just it just
from first principles this seemed like
the future. But um I think this current
this current race I think was definitely
based on like this not cult he started
but yeah more or less right this cult of
like agi or well again my reservations
for that but human level AI would be a
really potent thing that would like eat
the world and it&#39;s like oh that sounds
great maybe I could make a company that
works on that right and so he he really
helped with the marketing there but also
he he helped create a culture where like
hey we we have to assemble a team and
like make sure the right people are in
control of it and that appeals to all
sorts of, you
know, Yeah. Yeah. It worked. It worked
out well. It was really smart. So, he he
like whatever he was afraid of, he
activated the exact people he probably
does not necessarily want to to be doing
that. Um Um Okay, last question. Uh this
is a tough one because it kind of
depends on whether you guys fully
succeed or not. I mean, when we talked
before about the US and China kind of
being on their own
paths, you know, the more and more they
visit Europe and go to Europe, I mean,
it feels like a museum in some ways,
they don&#39;t even feel like they want to
participate necessarily in in this next
era. Um, they&#39;re sort of seeding it, as
far as I can tell, to to the US and
China. I don&#39;t think Russia I think
Russia has definitely the smart enough
people to pull this off but I don&#39;t
think has like the economic and and
um kind of like pragmatic wherewithal to
compete with these data centers at this
point. Um and then you know I don&#39;t
think anybody else necessarily does.
Yeah. I mean, do you
see do you see a world where this is
like a US China thing going forward or I
guess that&#39;s the entire one of the
entire points of what you guys are
trying to do would be to avoid a
scenario like that. I mean, well,
Europe, you know, right now they&#39;re
they&#39;re kind of captured by
decelerationist culture. It&#39;s full
spectrum. It&#39;s like anti-uclear, anti-
tech, anti-progress. I I think that has
to change, right? Like the the whole
thesis is that systems that have
cultures oriented towards growth succeed
and and are sort of selected for and
those that are against it are dissipated
and kind of pruned out of the
evolutionary tree of nations, if you
will. So it&#39;s either accelerate or die.
That&#39;s I mean we put it pretty simply
and I really hope like Europe kind of
has a cultural shift. I I know maybe
they don&#39;t like our our current culture
and so on, but may they&#39;re going to have
to have their own variant or or or
they&#39;re in trouble. Um, I think there&#39;s
also like, you know, the Middle East, I
don&#39;t know if you&#39;ve been there, but
they&#39;re going all in on like building
these data centers. They&#39;re trying to
transduce their their oil wealth into
compute wealth. And, you know, I mean,
for them, it&#39;s like they have a big
stake in the the cartes of scale. And
you know, what&#39;s going to create more
demand for energy is a machine that
turns energy into value, right? And if
we&#39;re creating the most efficient
machine at doing that, then from Javon&#39;s
paradox, there&#39;s going to be even more
demand for energy. So, I don&#39;t know,
that&#39;s like their game there probably.
Um, but they&#39;re they&#39;re they&#39;re full
acceleration, right? And obviously
there&#39;s there&#39;s ties between the the VC
ecosystem and and and and over there,
but um like I I think like there&#39;s the
two big players like duking it out,
right? And but like this this this
competition is actually what is setting
the pace for the acceleration of this
technology and then everybody kind of
wins, right, from it, right? like even
like the leftovers, the byproducts of
this race, it&#39;s like, oh yeah, this
model&#39;s like a year old, just going to
open source it and then anybody can
download and that&#39;s huge value other
nations wouldn&#39;t have had access to,
right? And that kind of that&#39;s the
rising tide that floats all boats,
right? And so of course like US and
China are going to like compete to have
like the most cutting edge stuff, but I
think it&#39;s going to it&#39;s going to help
everyone who&#39;s open-minded to it, right?
And that&#39;s why I&#39;ve been trying to scale
this culture of open-mindedness to AI
and embrace AI. It&#39;s actually out of
empathy because if you don&#39;t embrace AI,
you&#39;re going to fall behind. It&#39;s pretty
simple as an individual, as an
organization, as a nation. Um, that&#39;s
the message essentially. So, okay. Okay.
Thanks so much, man. No fun. Thank you
for bearing with us. Yeah, for sure. Our
guest today was Gil Fairone. Thank you
so much for being here. I am your host,
Ashley Vance. Core Memory is produced by
me and David Nicholson. Our theme song
is by James Mercer and John Sortland.
Our show is edited by
the wonderful, delightful John Sortland
and we are sponsored by Ewan Adventures.
Thank you all and we&#39;ll see you again.
</textarea>
        </div>

        <div class="mt-8">
          <div class="flex flex-col sm:flex-row sm:justify-between sm:items-center gap-4">
            <a href="../summaries/index.html" class="border-2 border-blue-400 text-blue-400 px-6 py-2 rounded-lg font-medium hover:bg-blue-600 hover:text-white transition duration-300 text-center">
               All Summaries
            </a>
            <div class="flex flex-col sm:flex-row sm:items-center gap-4">
              <a href="https://youtube.com/watch?v=5O5do_N07kY" target="_blank" class="bg-red-600 text-white px-4 py-2 rounded-lg font-medium hover:bg-red-700 transition duration-300 text-center">
                Watch on YouTube
              </a>
            </div>
          </div>
        </div>
      </div>
    </section>

    
    <footer class="bg-black text-white py-8">
      <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center">
          <p class="text-gray-400">&copy; 2024 PodPapyrus. All rights reserved.</p>
        </div>
      </div>
    </footer>
  </body>
</html>
