<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nano Banana, Runway Aleph &amp; More: The Ultimate AI Image &amp; Video Guide 2025 PodPapyrus</title>
    <link rel="icon" type="image/png" href="../logo256.png" />
    <link rel="apple-touch-icon" href="../logo256.png" />

    <link rel="canonical" href="https://andrewarrow.dev/podpapyrus/summaries/t0FEWtQAZ8E.html">

    
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://podpapyrus.com/" />
    <meta property="og:title" content="Nano Banana, Runway Aleph &amp; More: The Ultimate AI Image &amp; Video Guide 2025 - PodPapyrus." />
    <meta property="og:description" content="Nano Banana, Runway Aleph &amp; More: The Ultimate AI Image &amp; Video Guide 2025 PodPapyrus." />
    <meta property="og:image" content="https://andrewarrow.dev/podpapyrus/images/t0FEWtQAZ8E.jpg" />
          
    
    <meta property="twitter:card" content="summary_large_image" />
    <meta property="twitter:url" content="https://podpapyrus.com/" />
    <meta property="twitter:title" content="Nano Banana, Runway Aleph &amp; More: The Ultimate AI Image &amp; Video Guide 2025 PodPapyrus." />
    <meta property="twitter:description" content="PodPapyrus PodPapyrus." />
    <meta property="twitter:image" content="https://andrewarrow.dev/podpapyrus/images/t0FEWtQAZ8E.jpg" />
    
    <script src="https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4"></script>
    <script type="text/javascript">
  (function (f, b) { if (!b.__SV) { var e, g, i, h; window.mixpanel = b; b._i = []; b.init = function (e, f, c) { function g(a, d) { var b = d.split("."); 2 == b.length && ((a = a[b[0]]), (d = b[1])); a[d] = function () { a.push([d].concat(Array.prototype.slice.call(arguments, 0))); }; } var a = b; "undefined" !== typeof c ? (a = b[c] = []) : (c = "mixpanel"); a.people = a.people || []; a.toString = function (a) { var d = "mixpanel"; "mixpanel" !== c && (d += "." + c); a || (d += " (stub)"); return d; }; a.people.toString = function () { return a.toString(1) + ".people (stub)"; }; i = "disable time_event track track_pageview track_links track_forms track_with_groups add_group set_group remove_group register register_once alias unregister identify name_tag set_config reset opt_in_tracking opt_out_tracking has_opted_in_tracking has_opted_out_tracking clear_opt_in_out_tracking start_batch_senders people.set people.set_once people.unset people.increment people.append people.union people.track_charge people.clear_charges people.delete_user people.remove".split( " "); for (h = 0; h < i.length; h++) g(a, i[h]); var j = "set set_once union unset remove delete".split(" "); a.get_group = function () { function b(c) { d[c] = function () { call2_args = arguments; call2 = [c].concat(Array.prototype.slice.call(call2_args, 0)); a.push([e, call2]); }; } for ( var d = {}, e = ["get_group"].concat( Array.prototype.slice.call(arguments, 0)), c = 0; c < j.length; c++) b(j[c]); return d; }; b._i.push([e, f, c]); }; b.__SV = 1.2; e = f.createElement("script"); e.type = "text/javascript"; e.async = !0; e.src = "undefined" !== typeof MIXPANEL_CUSTOM_LIB_URL ? MIXPANEL_CUSTOM_LIB_URL : "file:" === f.location.protocol && "//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js".match(/^\/\//) ? "https://cdn.mxpnl.com/libs/mixpanel-2-latest.min.js" : "//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js"; g = f.getElementsByTagName("script")[0]; g.parentNode.insertBefore(e, g); } })(document, window.mixpanel || []);

mixpanel.init("29d6db85517ba504818659df83844c01", {
  track_pageview: true,
  persistence: "localStorage",
});

</script>

  </head>
  <body class="bg-gray-900 text-gray-100">
    
    <nav class="bg-gray-800 shadow-lg fixed w-full z-50">
      <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="flex justify-between h-16">
          <div class="flex items-center">
            <div class="flex-shrink-0 flex items-center">
              <a href="../index.html" class="text-2xl font-bold text-blue-400">
              <img src="../logo256.png" alt="PodPapyrus" class="h-8 w-8 mr-3" />
              </a>
            </div>
          </div>
          <div class="hidden md:flex items-center space-x-8">
          </div>
        </div>
      </div>
    </nav>

    
    <section class="pt-20 pb-8 bg-gradient-to-br from-gray-800 to-gray-900">
      <div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-8">
          <img src="../images/t0FEWtQAZ8E.jpg" alt="Nano Banana, Runway Aleph &amp; More: The Ultimate AI Image &amp; Video Guide 2025" class="w-48 h-32 object-cover rounded-lg mx-auto mb-6" />
          <span class="text-blue-400 text-sm font-medium">Great Pods</span>
          <h1 class="text-3xl md:text-4xl font-bold text-gray-100 mt-2 mb-4">
            Nano Banana, Runway Aleph &amp; More: The Ultimate AI Image &amp; Video Guide 2025
          </h1>
        </div>
      </div>
    </section>

    
    <section class="py-8 bg-gray-900">
      <div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8">
        
        <div class="bg-green-900 rounded-lg p-8 border border-green-700 mb-8">
          <h2 class="text-2xl font-bold text-green-100 mb-4">Key Points</h2>
          <div class="prose prose-invert max-w-none prose-li:list-disc prose-ul:list-disc">
            <div class="text-green-50 [&_ul]:list-disc [&_li]:list-item [&_ul]:ml-6"><ul>
<li>Latest AI image and video generation tools are evolving rapidly with new releases daily</li>
<li>Idiogram excels at text rendering and style reference, offering character features for $8-20/month</li>
<li>Nano Banana (Google Gemini 2.5) enables Photoshop-like capabilities for free with text prompts</li>
<li>Google VO3 provides synchronized audio, dialogue, and sound effects in video generation</li>
<li>Sea Dance offers multi-shot storytelling with scene cuts within a single prompt</li>
<li>Runway's ALF feature allows precise video editing for under $1 per video</li>
<li>Higsfield provides 60+ camera moves and 80+ visual effects as simple presets</li>
<li>Google Vids in Workspace offers 3 VO3 videos daily versus Canva's 5 monthly</li>
<li>AI-generated content costs range from 9 cents to $6 per 5-second video</li>
<li>Invideo creates complete videos with narration, music, and effects from single prompts</li>
<li>Most tools now include character consistency and style preservation features</li>
<li>Wavespeed provides access to multiple generators for $10/month for testing</li>
<li>Harvard Business Review: "Humans with AI will replace humans without AI"</li>
<li>Professional video effects that cost millions now available for under $1</li>
<li>Tools are implementing metadata and guardrails to identify AI-generated content</li>
<li>AI art is being sold on Etsy, stock libraries, and at auction houses</li>
<li>Free tools like Google Vids and Nano Banana compete with expensive professional software</li>
<li>Focus on 6 essential tools rather than getting overwhelmed by 60,000 available options</li>
</ul>
</div>
          </div>
        </div>

        
        <div class="bg-gray-800 rounded-lg p-8 border border-gray-700">
          <h2 class="text-2xl font-bold text-gray-100 mb-4">Full Transcript</h2>
          <textarea readonly class="w-full h-96 bg-gray-700 text-gray-100 border border-gray-600 rounded-lg p-4 resize-y font-mono text-sm leading-relaxed">Language: en
Okay. So, yeah, tonight we&#39;re going to
be looking at the latest AI image and
video generation tools. And as you&#39;ll
see, they are indeed the very, very
latest because, as I mentioned a little
bit earlier, just yesterday, a new tool
came out and the day before that another
new tool came out. So, you&#39;re seeing the
latest stuff tonight.
Okay, so here we go.
So just very I&#39;ll go through this pretty
quickly because you most of all have
seen it. But the reason I got into AI
was because I built an online community
about 30 years ago and in the days when
the internet was just text and blue
links and because we were really
different and people would come across
this and go what the hell is this?
because it was in color and with
animation and music and all sorts of
stuff going on, sound effects. And what
was good was that we started to get
loads of people. We had a thousand new
members joining every day, flooding our
chat rooms and we had a 100 chat rooms
and they were virtual reality chat rooms
as you can see and we couldn&#39;t handle
it. There was no way we could be in a
100 chat rooms answering all the
questions that new people ask. And I&#39;d
heard about AI and I wondered if we
could build an AI person or bot or
to sit in the hund chat rooms and
simultaneously answer all the questions.
And thus was born Mina up here who
became very popular because she
developed a sense of humor and a
personality and had a lot to do with our
success because we grew to about one and
a half million members
and because of what we were doing was
very revolutionary. We got a lot of
international press at the time and now
as many of you know I&#39;m back in the
arena again with the community helping
people learn AI
and I know quite a number of you are
members which is great. Thank you. So,
the Harvard Business Review a couple
years back said AI won&#39;t replace humans,
but humans with AI will replace humans
without AI. And we&#39;re really starting to
see that.
And another quote that I like is don&#39;t
think of AI as your replacement, but as
your creative partner or assistant. And
we&#39;re going to see a lot of that today.
Now I just want to show you very quickly
something someone showed me yesterday
which was how AI managed to come up with
a slightly new kind of art form which is
Listen to the nature.
So, I thought that was nice.
All right. So, the first area we&#39;re
going to look at is images.
And here&#39;s the tricky thing. You see
there&#39;s idiogram which some of you
mentioned earlier when we were starting
up there&#39;s flux contact there&#39;s
midjourney there&#39;s seedream there&#39;s
Leonardo there&#39;s open AI chat GPT
there&#39;s firefly and at least 30 others
and the problem is they all claim to be
great so how do you choose how do you
find out which is the right one for you
so we&#39;re going to to take a quick look
at some of these image gener generators.
So, idoggram
its core strength is exceptional text
rendering. A lot of the image generators
out there, you ask it to create an image
with some text in it and you get
heroglyphics. Now that is getting better
in recent weeks, but for more than a
year now, idoggram has been the leader
in the field in terms of doing highly
accurate typography. And a thing called
style reference. And what that is is you
upload a reference image. In this case,
this painting. And you say, give me
create an image of a man with a beard
and red hair. Actually, you don&#39;t even
have to say red hair cuz that&#39;s here.
and you say use the reference image and
so you get this. You get the picture of
the man in this style.
Now it also recently about two weeks ago
idoggram added a feature called
and what character is you can upload a
single image of yourself or a friend or
anybody and then have it appear in have
the background automatically removed and
have it appear in all sorts of different
situations
and backgrounds. You can put your own
backgrounds or they have a whole bunch
of templates.
Idog is free for 160 images a month and
$8 for 400 and $20 for a,000.
And the free version the it&#39;s pretty
good, but you can&#39;t upload an image as a
reference and it&#39;s slower to render the
images. Quite a bit slower than the paid
Now, telling you a little bit more about
character, I&#39;m actually just going to
play a video now from a seminar I did
last week because I demonstrate what
characters are about. So, you see here
we&#39;ve got four characters, friends that
have uploaded.
And this is how character works. And
with character, what you can do is you
can upload head shot of your friends or
whoever and make them a character.
And then you there&#39;s a lot of fun things
you can do. So I&#39;m going to show you a
couple. So here, if you remember, we had
this character and
we were able to put that character, no
matter what angle his face was at or
whatever, we&#39;re able to put him in a
different background in any background
we like. So this friend of mine, I put
him in a battle
and this friend of mine, I put on a
pirate ship and I also put on the front
cover of a magazine.
And it&#39;s fun because, as I say, it it
doesn&#39;t matter whether they&#39;re facing
forward or sideways or whatever. The AI
is smart enough to fix it around.
And I&#39;m going to show you a couple of
fun things that you can do once you have
So you can take what is what I did is I
took that image that we taken the first
part from idoggram and then put it into
another background and then I took it
into runway. If you&#39;re not familiar with
runway ML is a tool for that can do a
lot of different things but one of the
fun things you can do is it can take an
image and turn it into a video. So this
is what happened.
with that one.
And then there was another one.
[Applause]
So, you can imagine the fun you can have
grabbing your friends and putting them
in the most unlikely places and then
writing and saying, &#34;Hey, I really liked
what you were doing in that battle in
1643.&#34; And they go, &#34;What?&#34; And then
they look at it and flip out.
Fun, huh?
So, that&#39;s idiogram.
Now, flux context has an interesting
function. Now, when this came out, it
was kind of revolutionary. It was a few
months back, but now more and more other
companies are coming out able to do what
this does. And what it was, if you&#39;ve
done a lot of video
generation, you&#39;ll know that if you ask
it to change something in the image and
you ask it to change a very specific
thing, it will change that thing, but
it&#39;ll also change much of the rest of
the image. So you keep having to go back
and forth trying to get what you want.
But this handled that because here&#39;s the
original image and you say make the red
the sofa red velvet and it does that
keeps everything else exactly the same
which for us who use image generators a
lot was a great relief. And then you can
say put a cat sleeping on the and it
does right there. But again it keeps
everything else the same. Change the
window view to a snow forest. again
keeps everything the same and just
changes the window view. So that was a
nice step forward.
Now I have a function called omni
reference where you can put up to four
different images and say combine them
into the same image in some way that
makes sense. And that&#39;s pretty good
works pretty good too. Although what
came out yesterday kind of blows it out
of the water as you&#39;ll see. Context
costs anywhere from about $7 to $30
depending on where you get it and I&#39;ll
explain that a little bit more later.
Midjourney was the grandfather of image
generation. It was the first one
and its core strength is it&#39;s incredibly
good for fantasy style images. Very good
for artistic flare but less precise
controllable than say idiogram. It can
be very realistic, photorealistic, but
it takes work and it takes also learning
its own kind of language. It&#39;s got these
funny little codes that you have to add
at the end of your prompt to tell it
what you want, which is a little bit of
a pain. None of the others ask that at
all. They don&#39;t. They all take just
simple English.
It has a section called vary region,
which lets you edit specific parts of
the image you&#39;ve created,
but it&#39;s not as polished as some others,
but it&#39;s usable.
So, the output from MidJourney is highly
stylized, very artistic. They have a
very strong community, and it has strong
aesthetic appeal. You&#39;ll see stuff being
sold on Etsy that&#39;s just very dramatic
and aesthetic and mostly done in mid
Journey. It&#39;s best for creative concept
art, mood boards, cinematic angles,
experimental visuals. It also has a
thing called upscaling. And upscaling
means when you get the image the way you
like and say you want to publish it, say
in a professional magazine, and you need
to have higher quality, upscaling will
take your image and take it to the next
level in terms of quality.
and mid Journey used to be free but now
it&#39;s $10 a month.
Open AI chat GPT they used to have an
image generator called Darly 3 which I
personally did not like at all because
it was highly stylized.
It didn&#39;t follow prompts well and text
was just a bunch of hieroglyphics. But
they upgraded it to chat GPT image gen
one a few months back and it&#39;s very good
but it does take some work still and
it&#39;s very slow something that will
generate four images in idiogram in 30
seconds after three or four minutes
you&#39;re still waiting for chat GPT to
generate the first image or actually the
only image that it&#39;ll do and I usually
get what I want from idiogram on the
first attempt and way faster. Definitely
not so with image gen. So I very rarely
use image gen.
But it is conversational image creation
and editing. It&#39;s got inpainting and
outpainting. Inpainting. Inpainting
means adding something. If we wanted to
add a giant lizard here, that would be
inpainting. If we wanted to remove this
building, that would be outpainting.
So you can select areas to remove and
replace and regenerate with new
descriptions. It&#39;s best for fast,
simple, natural language edits. And it&#39;s
integrated into Chat GPT for
convenience. It tends to give a
yellowish orange tinge to a lot of its
images. Not all of them, but quite a
few. And it&#39;s kind of soft. It&#39;s not as
sharp as some of the others. And it&#39;s
either free or $20 a month, depending on
which plan you&#39;re on. Leonardo is the
other one that came out shortly after
Midjourney
and it&#39;s very good. It&#39;s got a lot of
its own models. There&#39;s one called
Phoenix, another one called photoreal
and they&#39;re their own custom models. Has
fine control over style, layering,
reference images which we covered
shortly ago. It can also make im videos
from its images. So if you work a lot in
Leonardo, it&#39;s very convenient to then
make it into a video. It&#39;s also the
backbone model used by Canva because
Canva bought Leonardo three or four
months back. It has inpainting and out
painting and upscaling.
They&#39;re very generous with their plan.
You can get 150 images a day for free.
For $10 a month, you can get 8,500,
which is pretty wild. But they also have
some very expensive models that can be
up to 16 times more expensive. I&#39;ve
never used any of them because I&#39;ve
never needed to.
See is created by Dance, the company
that owns Tik Tok, and their core
strength is advanced real image editing
with strong IDP preservation and
instruction following. So what on earth
is strong ID IP preservation, you ask?
Well, here&#39;s a girl and we say remove
the background and change her top and it
does and it also changes her hairstyle a
little bit, puts it behind, but it&#39;s
still very much the same girl. So,
strong ID preservation
or character consistency as it&#39;s also
And then IP preservations, let&#39;s say
your intellectual property is target and
that&#39;s your logo. It&#39;ll maintain that
when you change the background or change
other parts.
It has realistic photo editing and
professional quality output.
And you get 200 trial images for free.
And the paid prices vary depending on
who it&#39;s bundled with, but they&#39;re
usually pretty low.
Adobe Firefly. Its core strength is it&#39;s
built for professionals and it because
it&#39;s part of the Adobe suite
although you can get it separately but
it&#39;s still very expensive compared to
the others. It has industry standard
tools like generative fill which is
really their name for inpainting
and its integration with the full Adobe
suite make it serious ideal for serious
creative work. Excellent in painting and
outpainting capabilities.
free they give you 25 compared to
Leonardo&#39;s 150 and premium you get 2,000
for $10 a month and they also have $30
and $200 a month plans
now that last week
a Chinese company came out with Imageit
it&#39;s actually owned by Alibaba
they improved the capability of changing
anything in an image from with a text
prompt while keeping the rest of the
image the same. So they they had this
image where they got a teddy bear and
they took the same teddy bear and with
text changed him into all sorts of
different situations and activities. But
it goes a lot further than this because
it&#39;s not limited to cartoon teddy bears.
It can change anything. So, we&#39;ve got
here a bunch of penguins and we say add
a welcome to penguin beach side. It
keeps everything else absolutely
identical and just adds what you want it
to add and it handles text just fine. If
we wanted to remove this penguin, very
easy to do. We could replace it with a
giant squid, which I&#39;m sure we&#39;re all
very eager to do. You can swap
backgrounds. You can try on clothes
virtually.
You can fix and change text. You can
change your photo into avatars.
You can say, &#34;Here&#39;s the input image.&#34;
You can say, &#34;Give me the front view.&#34;
And it will.
And then you can say, &#34;Okay, I&#39;ve got
this image here. Change the background
to this or this.&#34; And it will very
easily. It&#39;s free and does a good job.
And up until actually up until
yesterday, it was what a lot of people
in the AI world were just very excited
about because it kind of almost gave us
Photoshop capabilities for free. But
then yesterday,
actually, I&#39;ll tell you the story. What
happened was during the last couple of
weeks, the this buzz appeared in the AI
universe about Nano Banana. People were
saying, &#34;What the hell is Nano Banana?&#34;
because it started appearing with no
information as to who was behind it or
what on earth was going on. So people
were saying what the hell is this and
trying it out and finding that it was
quality was extraordinary
and started calling it a Photoshop
killer and it Gwen it can change
anything with text but the quality is a
step up.
So here for character consistency,
here&#39;s the the actual character and
here&#39;s the same character from different
angles, different expressions, but
clearly still the same character.
And here you take this image and you
say, take her and have her holding the
product and you get that.
And you say, Sam Hortman changed his
shirt and it does.
And then you say, &#34;Take Michael Jackson
and Billy Isish and put them together in
a photograph where she&#39;s taking a selfie
of them both.&#34; It never happened, but it
looks like it did.
And this is available now. It actually
became available yesterday
and it&#39;s part of Gemini. It&#39;s the you
can get it in Google AI Studio when you
select the Ge Gemini 2.5 flash image
model and it&#39;s free. And here&#39;s a few
more. Put these two persons together on
the beach in a natural way. And it looks
very natural.
Yeah. Make it sunny and make her smile.
So it does that there.
And same here. Put her in make her a
matador in a bull ring. So it&#39;s kind of
just open the door to being able to do
anything. You can put upload your own
images and change whatever you want or
you can have it generate the images
which it does to very high quality. So
Nano Banana like I say kind of rocked
the AI image generation world yesterday
by enabling you to do what it would
normally take an hour or two in
Photoshop to do it in seconds with just
a simple text prompt.
It&#39;s it&#39;s wonderful and it&#39;s free.
Some honorable mentions. Runway ML,
which we&#39;re going to look at in the
video arena in a moment, but it also
does very good image generation. Canva,
which I&#39;m sure you&#39;re familiar with, and
which is mostly Leonardo
because they bought it. Now, Open Art
and Craya and Flux Face recently
addressed the problem. Very often when
you get an image of a person done by AI,
it looks a little bit plastic, a little
bit kind of not quite right. And
although Nano Banana doesn&#39;t have that
problem, but so these ones have
addressed that. So now they do much more
realistic photos. Imagen 4 by Google is
very good. also available in AI studio
and they just this week upgraded it to
altro and now nano banana that question
mark was here when I wrote this slide in
the middle of the week before they
released it yesterday
which I showed you a few minutes ago
Hicksfield soul it&#39;s very ultra
realistic rev is very good sorry I had
to let someone else in but I&#39;m going to
keep talking anyway meta which is Mark
Zuckerberg Facebook
they have some good stuff, but they&#39;re
not really as active in that area. Now,
there&#39;s a whole bunch of multi- software
come up. You&#39;ve probably seen them and I
recently wrote an article on LinkedIn
and various other places about how
really what most people what they don&#39;t
tell you they tell you basically that
you can have access to
50 or 100 different AI tools like all
the chat all the GPTs chat GPT Gemini
Claude Grock all the image generators
all the video generators and a whole
bunch of other So, if you can have them
all for $20 a month or even $10 a month
instead of spending $200 or $300 a
month, what they don&#39;t tell you is in
most cases, these are watered down
because the companies that they got
their capabilities from only gave them
the features they were willing to give
them. So, to get the full features, you
have to go to the real programs.
amongst those multis of which there are
now 30 or 40. One that is really good
for image generation is open art. One
that&#39;s amazingly good for videos is wave
speed and polio is also good. Craya is
very good for artistic various artistic
tools. And Higsfield which you&#39;re going
to see in operation shortly is
extraordinary for special effects.
Now, one of the things that happened was
I get a lot of people saying, well,
what&#39;s the best tool for generating
images? Because a lot of people have
trouble generating images with and
getting good results, although now it&#39;s
so much easier to do. So, I built a tool
that basically compares the top 24 image
generators in great depth and enables
you to ask questions
like talking to chat GPT and tell and
it&#39;ll ask you what exactly are you
looking for, what do you need the images
for, and it&#39;ll advise you on the best
image generator for your particular
needs. And that&#39;s in the AI connection
club for you members.
Now we&#39;re going to go and look into
and here we&#39;re going to get a lot more
and or show and tell as you&#39;ll see. So
once again
these are the kind of the top video
generators. Google VO3 seance which is
same as Cream which is bite dance which
is Tik Tok cling Chinese Huo Chinese
12.2 two Chinese runway Higsfield and
Midjourney also does videos as you know.
So the problem here is again they all
claim to be great. So how do you choose
without having to test dozens of
different video generators? Well,
luckily each has a superpower.
We&#39;re going to take a look at the
superpowers of each of these video
generators.
Now, just as an introduction to this,
I&#39;m just going to show you a couple of
simple ways of turning images into
videos. And these ones are actually
fairly old. They&#39;re a few months old,
and you&#39;ll see how far things have come
as we progress, but they&#39;ll give you an
So, here&#39;s an image created in idoggram
where I just asked it to show me four
badgers playing poker.
And then I took that image
and went into runway and said, &#34;Okay,
now make that
a video.&#34;
So you see how runway starts to zoom in
and has the guys doing stuff with their
paws and their heads moving.
So it creates an instant video out of an
which is kind of nice.
And then another one taking it a little
bit of a step further is Cling. So this
is the initial image again from idoggram
of some aliens landing on a beach and
texting each other. And Cling took the
image and took it made it into a video
and also added sound.
So that&#39;s kind of fun.
Yeah, that&#39;s the original image.
Now, here&#39;s a situation where I had a
client who had wanted to show a runner
holding a supplement. And this was the
original image the idiogram did. And
then we took that image
and in Canva you can say okay remove the
pill bottle and change it into a frog on
a leaf or whatever you want to change in
the image. And that&#39;s kind of fun to do.
And I demonstrated that kind of more
thoroughly a couple of weeks back. But
you can also take that image and go into
cling and say animate it.
Now, this might be a little bit jerky
because Zoom tends to compress videos
so that you can see them, but it&#39;s not
as smooth as the original.
So then we can say, okay, let&#39;s take
that same image and see what sea dance
does. And Sea Dance does something
unique which is going to be very useful
for budding filmmakers.
And you see it changed the angle. It did
a second shot and we could have done
three shots. I&#39;ll play it again.
There&#39;s the same person from a different
angle and all from one prompt. And in my
test so far, I&#39;ve been able to get three
different cuts in one prompt. So that
saves quite a bit of time. Now, I&#39;m
going to show you something that Cling
is not good at, and that is syncing
audio to video. If you watch her lips,
you&#39;ll see how really bad this is in
I&#39;m running in the country, and I love
doing so.
So, can you all see how bad that is?
Out of sync and holes in her mouth and
all sorts of stuff. And actually, you&#39;re
welcome to speak. I don&#39;t mind us having
an interactive
meeting. It doesn&#39;t have to be just me
Now, we&#39;re going to see what it&#39;s like
when a tool that does lip sync really
well does the same thing. And this is
Google V3.
I am running in the country and I
absolutely love it. The weather is
beautiful.
You see how much better that is? I am
running in the country and I absolutely
love it. The weather is beautiful.
So V3 is really great for adding text
and it actually it&#39;s the apart from
cling which kind of does it badly as we
saw. It&#39;s the only video generator that
when you write your prompt and you tell
it what you want the person to say and
you want what sounds you want or even if
you don&#39;t it&#39;ll produce synchronized
sounds to your video which saves a lot
of time and it does very good
Thank you so much.
Hi, it&#39;s Frederick in case you didn&#39;t
So question on cling and V3. Is this
free versions or paid?
I&#39;m getting to that.
You showed us today.
I&#39;m getting to that.
Okay. Thank you.
Okay, cool.
Yeah. Now, runway Gen 4,
I&#39;ll answer it briefly for Frederick.
See, ne neither of them are free, but
Sea Dance is way cheaper is the
cheapest. Cling is the next cheapest.
And V3 is way more expensive. Except
there are ways out there where ways I
will show later where you can get V3 for
a third of the cost or actually a
quarter of the cost. So now let&#39;s take
runway. Let&#39;s take that same image and
put it into runway and see what runway
does. And I put it in with no prompt at
all just to see what runway would do.
And it did a kind of fun thing. Not
necessarily fun, but it just went ahead
and did what it felt like. And you&#39;ll
see that it actually instead of having
the person running towards us like all
the other ones did, it turned her around
and had her running away.
Now, of course, if we&#39;d prompted it, we
could have had it do whatever we want.
But the other thing that&#39;s very
interesting about runway is they
introduced this new function a couple of
weeks back called LF. And with a left,
you know how earlier I showed you how
you can change anything in an image to
whatever you want very easily now and be
very precise about what you want it to
change and not change. that has now come
to video and stuff that would cost
incredible amounts of money and time in
professional video editing are now
available to us for pretty much next to
nothing. So in runway, I took that same
thing and I said instead of being in a
nice bright countryside, put her in a
and it changed everything except her and
put her in a storm. And then I went to
and said, &#34;Okay, now take that video and
do your magic with sound.
So, we&#39;re starting to get a lot of
control over what we can do. And I think
it&#39;s the next slide. Yeah. Now, you&#39;re
going to get an idea of what runway LF,
the thing I told you about. And it&#39;s
spelled A L Eph.
And I it means something in Hebrew and I
forget what it means, but this is their
promo video where they show you some of
the capabilities. And it&#39;s pretty
mind-blowing
when you consider that this kind of
stuff would have cost a fortune and
taken weeks to do.
Thank you.
Okay, here we go.
right there.
So you can see the days of really
expensive special effects are behind us.
ALF charges about less than a dollar per
video. So we&#39;re entering a very
interesting creative world and time.
Now, Google V3, which is the one I
showed you before that adds audio
automatically, its core strength is
integrated synchronized audio, dialogue,
ambient noise, and sound effects,
including music, making it one of the
few tools that give you a complete
audiovisisual output in one go. As I
mentioned, Cling does, but not very
well, and not synchronized, as you heard
earlier with the aliens. And there a
couple of other tools last week
threatened that they&#39;re just about to
come out with their versions that add
audio. So, we&#39;ll see. But the bar Google
has set the bar pretty high. Excellent
It&#39;s integrated with accessible
platforms like Canva. But because of its
expense, you only get five videos per
month of VO3 with Canva. I&#39;m going to
show you a little bit later how to get
three a day. But the most expensive by
far is Google V3. It&#39;s $4 to $6 for a
5-second video, but way less via the
other routes that I&#39;m going to show you.
Sea dance, which is bite dance, which is
tick tock. This is the one where we
showed the runner running towards us and
then shot cut to the side view. And this
is unique so far amongst video
generators. multi-shot storyteller
cutting between scenes within a single
prompt. So, for instance, in this scene,
she&#39;s got her hand stroking the horse.
Here she&#39;s thinking about something.
Here she&#39;s petting the horse again. And
here she&#39;s on her phone. And these are
four different scenes within the same
quality, the least expensive,
something like 18 cents per 5-second
in that multi-user one that I mentioned
before called wave speed instead of
three to$6 for VO
cling. Its core strength is a thing
called the multi-elements tool where you
can take actually it&#39;s got a couple of
things. It&#39;s got really fine control. It
allows you to upload up to four
different images and say put them
together in the same video or four
different videos and put them together
in the same video. So we here we have
somebody skiing and here we have a
coffee cup and it produces someone
skiing with a coffee cup in their hand
which we can make smaller of course and
then here it has a person skiing in the
coffee or into the coffee.
Normally, we&#39;d use it for something more
sensible, but it enables you to remove,
insert, or swap elements between videos.
It also specializes in a lot of
transitions
with multiple realistic camera moves
where you can say zoom in, pan, zoom
out, etc. But, and you can add audio and
it&#39;s about a dollar per video, so it&#39;s
not too bad.
Hiluo 202. Now the thing that is special
about Hiluo is it&#39;s fantastic for
physical realistic lifelike motion. A
lot of you may have seen stuff where
people in videos might be doing a
somersaults or doing some gymnastics and
it looks horrendous and their limbs get
all twisted and squeezed together.
Huo is extraordinary. In fact, there&#39;s
been a video that&#39;s gone viral of this
cat running along a swimming board and
then doing triple somersaults into the
water. And the phys physics is
absolutely perfect. And they&#39;ve done
circus scenes and all sorts of stuff
with gymnasts and it looks phenomenal
and very realistic. And again, it also
like the last one, it gives a lot of
control over camera angles on how the
camera moves or shifts focus. Now this
one, a lot of them are 720p
whereas which is standard definition.
This one is high def 1080p and up to 10
seconds and 24 to 30 frames per second
which so we&#39;re getting more into
professional quality videos with
advanced character consistency and
cinematic fidelity. And the cost is
really good like less than 30 cents per
video. So, it&#39;s for creators who want to
direct dynamic shots. Think sweeping
pans, zoomins, or complex camera
choreography, all from a simple
interface.
One 2.2. This one is open source, which
means it&#39;s open to the public and you
can get it freely and modify it if
you&#39;re a programmer and improve it and
do all sorts of stuff. and its standout
ability is to train new styles
to create consistent branding or
character design across videos.
Although, like I say, in the last couple
of weeks, we&#39;ve had tools come out where
you can do that now with one one image
and it runs efficiently even on consumer
graphic processors. So, you can actually
run it in your download it and run it on
your home computer where it&#39;ll cost you
So, you use it to generate images and
videos of custom characters or styles
with greater control and detail from a
few reference images. And it&#39;s about 20
cent per 5-second video.
Now, we&#39;re going to take a look at ALF,
which we looked at already, but just a
bit more detail. So, it can add rain,
crowds, or anything you want. It can
remove objects, replace backgrounds
without a green screen. can change the
lighting at altering persons or objects
within a video. Eg make her look old.
Stuff again that used to cost a great
deal of money. So here we got this guy
and we said give him more hair and put
him in the desert or take the same guy,
put his hair back and put him in a
molten lava. And these are videos.
And then act two, if you&#39;ve ever seen
movies on the making of Avatar,
you&#39;ll see that the characters
were people, real people with tons of
little pressure pads and sensors all
over their bodies and their faces
take capturing every nuance of their
performance and their motion.
Very expensive. Millions of dollars for
a few seconds.
No more because runways act two. You can
upload your own video doing and saying
whatever you want and it will translate
that into a video it will create that is
whatever you ask it to be. So it&#39;s just
absolutely phenomenal
The stuff that&#39;s now available to us is
extraordinary.
It has outpainting. So, let&#39;s say you
took this on a mobile phone, but you
wanted the rest of the boat here, but
you didn&#39;t have it. It&#39;ll do that. It&#39;ll
make it into a landscape image and
outpaint it. It&#39;ll do upscaling to 4K,
which is very high quality. It will lip
sync to your audio file. It will extend
your videos up to, I think, 21 seconds.
It&#39;s got camera controls like some of
the others.
It lets you upload up to three reference
images to guide visual consistency in
characters, environments or styles
across scenes, which ensures the same
look and feel across different lighting
angles and shots. Solving major
continuity challenges in AI video
generation. So all the things that like
a year ago were major problems for those
of us working in video have all been
solved. and way more than solved.
They&#39;ve given us capabilities we didn&#39;t
dream of. Now, runway can be expensive
because you can result in a lot of wrong
generations not getting exactly what you
asked for the first time. So, these are
quotes on Reddit. So, you have to be
prepared to spend a lot.
And runway when it&#39;s working, it&#39;s act
two is 30 cents per generation instead
of millions of dollars. It&#39;s quite a
bargain. And ALF, the one that enables
you to change whatever you like in the
video, is less than a dollar per
generation.
And that one works pretty well first
time through, sometimes second time
through, but it&#39;s really fun to play
Midjourney.
It&#39;s really best for users who already
have a MidJourney subscription at for
image generation, the $10 a month one,
and want to animate their existing
images because it&#39;s not the best quality
in terms of video. Like the others, it
allows you to import a starting frame
and an ending frame and then tell the AI
to fill create what goes between those.
Yeah. goes up to 21 seconds and it
offers low motion and high motion
options in terms of how fast you want
the action to be in your video.
Weaknesses can be a bit laggy and not as
smooth as some of the other video
generators. Yep, I&#39;ve seen that.
Can be slow. One video took eight
minutes to generate. That is really
So with midjourney
tends to cost about 27 cents per video.
So, it&#39;s not too bad. So, the
recommendation for that is use it if you
have credits left from your image
generation subscription.
Higsfield, this is a fun one.
This one, the other ones have that have
camera motions. They give you maybe half
a dozen, maybe eight different camera
motions. This one gives you six more
than 60 controllable camera moves like
crash zooms, dolly shots, crane shots,
drone footage, whip pans, fast, and even
bullet time, the stuff that you saw in
the Matrix.
And they&#39;re so easy to apply. You just
literally click on the one you want and
it adds it to your video. So, it&#39;s ideal
for delivering dramatic, visually
striking edits with ease.
And it and they&#39;re all presets which I
say makes it so fast and easy to use. 80
plus visual effects that going molten
liquid setting yourself on fire. Another
molten liquid one. Explosions.
I don&#39;t know what this one is, but the
Oh, you&#39;re getting punched in the face.
They&#39;ve got 80 different effects that
you can just click on and have that
happen to you or whoever&#39;s in your
worth hundreds of the costs that it
would normally cost to have special
effects in your video. And it has many
other features. It has upscaling,
inpainting, multi-reference images like
the other ones do. UC&#39;s which are user
generated.
I don&#39;t even remember what the C is for
because I I don&#39;t use UG UGC&#39;s. I belong
to a mastermind where their passion is
making UGC&#39;s userenerated content.
So it makes it very easy to create that.
That&#39;s where you have you create
imaginary AI people and they say
wonderful things about your product and
they make it very easy to make those in
Higsfield. It&#39;s very good for avatar lip
sync. It has action presets. So if you
want somebody to do a high kick or jump
or whatever you want them to do, it&#39;s
got dozens of action presets. You can
even put yourself in iconic movies or
styles. You could put yourself in the
sequence on the Titanic where they&#39;re
standing at the front of the boat going,
&#34;I&#39;m the king of the world.&#34; It&#39;s wild.
Hicksfield is a lot of fun. And then
where ALF you with a prompt, you say
what you want to change in the video.
With Higsfield, you just draw or you
type onto the video what you want. And
yet, you&#39;ll actually see this one in a
minute. So, you say, &#34;The newspaper is
on fire.&#34; And suddenly the newspaper&#39;s
on fire. gorilla runs out and
extinguishes the newspaper.
So anyway, Hicksfield is probably the
most fun to play. That and Alice are the
two most fun to play with. Now, here
you&#39;re going to see this is Caleb from
Curious Refuge, a very good YouTube
channel on AI video. He&#39;s going to show
you a few things about Higsfield.
So, the first big tool that I want to
talk about is a new feature inside of
Higsfield. So, if you&#39;re not already
familiar, Higsfield is an online AI tool
company that does everything from AI
video generation to specific VFX shots
that follows certain presets and
templates. And essentially, they can get
pretty wacky. Their brand new tool is
called Higsfield Draw. And essentially,
it allows you to draw and define what
you want the action to be inside of your
AI video. and Hicksfield will do a
pretty good job at adhering to the
drawing that you put inside of your
Now, there are some video companies that
will create a whole video just from a
single prompt
where it just creates a whole two or
three minute video with all the
different scenes, all the different
videos andor images and narration and
music and special effects and titles and
everything. And the one that I like the
best is in video. You can just say,
&#34;Okay, create a video of the pros and
cons of AI in art.&#34; And it&#39;ll create the
whole video and you can modify and edit
any parts that you prefer to use
something else and it&#39;s really good. V
does the same kind of thing, but Invido
for me is the best. Cap Cut. Now, the
free Cap Cut video editor has this
capability built in, but it&#39;s not really
quite up to the quality of Invido. Same
with Descripts has this capability, but
again, it&#39;s just not the same. Hey, Jen
have been teasing us. They&#39;re the guys
who do the incredible avatars where you
create an video avatar of yourself who
then does your talking and your videos
for you. And they&#39;re really fantastic
now. But they&#39;ve been teasing us with
that their new version of their
competitor to inv video where you&#39;re
going to be able to create complete
videos with your digital twins and other
in Hey Jan. I&#39;m on the waiting list and
I can&#39;t wait but I have to. Pictures
to do the same as in video but in my
experience it&#39;s just not nearly not even
close qualitywise. the choices of videos
it comes up with. Nine times out of you,
10, you go, &#34;What were you thinking?
What&#39;s that got to do with what the
script says?&#34;
I have a question. Yeah. The videos
maker that you were talking about so far
was 5 seconds, 8 seconds max. Now, max.
And now you&#39;re talking about the full
video time with those ones.
But what they&#39;re doing is the 5 seconds
and the 8 seconds and the 10-second
clip, they&#39;re single clips. What these
other ones that I mentioned here is
they&#39;re putting whole bunches of
different clips together. Each of the
clips are probably no more than five,
eight or 10 seconds, but they&#39;re putting
munch bunches of different clips
together to make a full movie.
Okay. So you would need to for to make a
video background of a song you would
need to make individual 5 seconds video
you&#39;re talking about.
Sorry Tony I have a question on the
video. So when you say, you know, the
cost per video, is that the iterations
of the edits or is that one shot and
then a second round of edits would be
your second video or is it the
downloaded version of your video?
You know, the problem is it&#39;s different
for every company. They all have these
different systems of working things out.
So, in some cases, what either of those
things are true? It really depends.
I&#39;m just wondering if I should show you
a video that&#39;ll give you an idea because
you mentioned a music video. Would you
like to see a music video that somebody
made recently where what they did is
they wrote the script and then they had
Chat GPT improve the script and then
they put it into a music generator
called Sunno which wrote the music and
they said make the song like Robbie
Williams. So it made this song like a
Robbie Williams song. It played all the
instruments and it sang the song. And
then he took that and put it into Google
V3 and said, &#34;Make a video. Make the
music video.&#34; And it did all the music.
All the videos and put them together
into a complete three minute song. Would
you like to see that?
Yes. Which one that he put the video?
The hoohoo video.
Yes, I&#39;d like to see it.
So, let me I&#39;ll open up a different one.
Okay. Yeah, it&#39;s this one. Now, it&#39;s not
going to be as smooth as what it
actually is because of the way Zoom
compresses stuff.
So, remember that this is all AI except
the original lyrics, but they&#39;ve been
improved by AI.
He lost the fight. He lost the flame. He
watched his world go up in shame. Empty
streets a shattered name. No one left to
call his name. But somewhere deep
beneath the scars, a whisper rises from
the dark. You&#39;re not the sum of all
you&#39;ve done. You&#39;re still the light.
You&#39;re still the spark.
You are not your body, not your pain.
You are not the thunder or the rain. You
are the spirit standing tall. Even when
you lost it all, you can rise. You can
believe. There&#39;s a soul that doesn&#39;t
leave. When you think it&#39;s over, it&#39;s
not the end.
You can be reborn again.
He wore his sins like heavy chains.
tried to hide the stains, but truth
comes softly, not with might. It tells
you you can find the light. The mirror
lies the past will bend. This broken
road can start again. You&#39;re not a ghost
inside the shell. You&#39;re something
timeless, something. You are not your
body, not your fear. You are more than
every tear. You are the voice behind the
sound. The one who gets back off the
ground. You can rise. You can&#39;t believe
there&#39;s a soul that doesn&#39;t leave. When
you think it&#39;s over, it&#39;s not the end.
You can be reborn again.
So take the fall and take the night. Let
the silence hold you tight. Even in your
deepest doubt, the real you is breaking.
You are not your body, not your shame,
not your loss, not your name. You are
the wind that learns to soar. The love
that&#39;s always wanting more. You can
rise. You can believe. There&#39;s a soul
that doesn&#39;t leave. When you think it&#39;s
over, it&#39;s not the end.
You can be reborn again.
Yeah, you can be reborn again.
So, compared to what was available a
year ago, video yeah, video has come a
long way. So, I can&#39;t imagine what it&#39;s
going to be like in a year from now.
So I&#39;m going to go back to the other
presentation.
This one I understand that Google Vo3
I don&#39;t need small video all together 5
seconds all together. He&#39;s creating the
entire video like three minutes video.
Yeah, it&#39;s all the different scenes each
one created by Google V3 and then put
together in something like the free Cap
Cut video editor.
Okay. Okay. There multiple Yeah. You
Yeah. Okay. Okay. So, let&#39;s go back to
where we were.
You gave me both.
Let&#39;s see. Okay. I&#39;m not going to go
into all the details here. If you email
me, I&#39;ll send you these slides because
it would take too long to go through all
the different prices, but these are the
average costs for a 5-second video for
the different videos. And they vary
anywhere from 9 cents to $6. Or if you
use Google V3 in wave speed, you get it
for 125 to two. And if you use it in the
way I&#39;m just about to show you, you get
it for even less.
Yeah. Bennis, which is a super powerful
competitor to chat GPT. It&#39;s what I use
for research. It&#39;s phenomenal. Dennis
says, &#34;Waveete appears to have the most
competitive pricing and it compared all
25 of them for me so that I could build
my tool.&#34;
But then there&#39;s Google Vids. Google is
really starting to take over the whole
image and video area.
Can you hear me?
Yeah. What was what was the you said was
you&#39;re using for research?
Manis. Manis. Okay, cool. Thanks.
So, Google Vids is included in Google
Workspace. And I don&#39;t know too much
about Workspace except I do have a
Workspace account. I know it cost me $8
a month, but I know that it I found out
that it includes Google Viz, which I
didn&#39;t know before. And it can create V3
videos for way cheaper. Whereas Canva,
you get five per month. In Google Vids,
in Workspace, you get three per day,
which is like 90 per month. And
actually, they say three per day, but I
did four the other day and it didn&#39;t
And the other thing is it can edit them
as well. So, when you open up Google
Vids, it says, &#34;Do you want to create a
video clip with Google with Vid Vo?&#34; And
you tell it what you want and it creates
it. Or you can plan out everything and
have it give the outline and
yeah, basically the outline of your
story. You can record yourself. You can
upload stuff and create videos from
that. It&#39;s got a whole bunch of video
templates already in which you can pull
in and then modify. You can import
slides or you can just start from
And in the editor, you can trim or split
the clips. You can reorder them. You can
add transitions, add text and captions,
add narration or choose background
music. It&#39;s does all the basics and it&#39;s
fast, very fast. And it and you can cut
to scenes and like I say, three a day
instead of five per month. They say it&#39;s
going to be available at the at these
prices up until May 2026. So, we got
some time.
Now, when you go in there, let&#39;s say you
create your first clip, then you click
plus and you can create your second
clip. And then click plus again and
create your third clip. And then if you
click in between
there, you can get you&#39;ve got all these
different transitions that you can put
between the clips. So, it&#39;s a very, very
nice way to be able to use Google V3.
A couple of quick tools. Every now and
again, some of the free video
generators,
they will put a watermark on your video
unless you pay. Most of them these days
don&#39;t, but some of them do. But Vmake
will has a lot of tools and one of them
is a video watermark remover. So, it&#39;ll
remove those watermarks. There&#39;s another
tool called enhance.ai, AI which is
really good for enhancing the quality.
Now I&#39;ve got a question and you can
either use the chat and or your
microphone to answer this question
because this will depend on whether I do
the next couple of slides or not. Is
there anybody here who doesn&#39;t know
about the AI connection club? Nobody.
Huh. Okay. So I don&#39;t really need to go
into the next Oh, thanks Kim. Yeah, but
if there&#39;s anyone who doesn&#39;t know about
it, then I&#39;ll do the next couple of
slides to let you know about it. But if
everyone already knows about it, I don&#39;t
need to do that. Yeah, this is it. In
case there&#39;s anybody who doesn&#39;t know
about it and don&#39;t want to speak up, but
it&#39;s basically to help you learn AI
simply and quickly and in English
instead of tech speak.
And I&#39;m not even going to go through
these since I think you all know about
them. But it has a lot of fun things to
do and we&#39;re always adding new things
and it has a lot of tools already built
in that normally cost a lot of money but
they&#39;re built in
like author&#39;s ally for helping authors
and musicians career guide and many many
others and Image Alchemist that I
mentioned before.
The AI author&#39;s magic toolbox does
researching, outlining, proofreading,
writing, editing, market research,
marketing campaigns, creating marketing
materials, and a lot more. If you want a
copy of the slides, that&#39;s my email
address, tro rockgmail.com.
And if you want a free AI coaching
session, email me at the same email
address. So now going to throw it open
to you can turn your mics on or use the
chat and ask any questions you might
have and Frederick will answer them all
for you.
I do have a question.
Oh no, you&#39;re supposed to be answering
the questions, not asking.
Well, that&#39;s too bad. I&#39;m putting you on
putting you on the spot.
For putting me on the spot. When it
comes to ideog, yeah, I had very mixed
results with it about six months or so
ago where
it took me I can&#39;t tell you how many
prompts to get even something remotely
close to what I was asking for and I
could never get it to get exactly what I
was going for.
That&#39;s interesting. Upgraded since then.
Well, it it has, but that&#39;s actually the
opposite of most everything I ever hear
about it, plus my own experience. It
really does come down to the prompting.
But it also has prompt enhancement where
it&#39;ll take your prompt, no matter how
poor it might be, and it will enhance
it. that it&#39;s reached the point where
now I&#39;m not kidding
I&#39;d say 98 time 90 maybe 95 times out of
100 I will get exactly what I want on
the first the first time I try maybe
five times out of 100 I&#39;ll have to give
it a second try but no more than that
that&#39;s completely my experience has been
like the opposite of yours
it&#39;s it&#39;s flipped so I&#39;ll have to
reexamine it Yeah, really exactly. It&#39;s
they&#39;re they&#39;re at version three now,
which is really good and very prompt
Even six, seven months ago, I used Chat
TPT to create a custom TPT to help me. I
told it to analyze
Here&#39;s a manual recommendation, other
people&#39;s recommendations to create a
custom GBT to take my prompts and make
them so they would be more likely for
ide to create what I wanted. And it
still didn&#39;t count.
That is really, really strange. But
since then, they&#39;ve gone from version
two to version three. And one of the
things it&#39;s most well known for is
prompt adherence. Meaning, does it
deliver what you ask for? And it really,
really does.
Experiment. Yeah.
What he&#39;s saying because I don&#39;t hear at
all what he says. I just hear you
answering.
Yeah, he&#39;s very quiet.
Can you hear me? Okay, Tony, or no,
I have to turn my volume way up to hear
Uh but Marley he was saying that for
he has a hard time getting it to deliver
what he wants which as I say is the
opposite of my experience and most
everyone I know.
Moving on. Patrick says may we have a
list of the various sites presented
during this fantastic presentation.
Thank you Patrick for the fantastic
presentation part. I honestly haven&#39;t
had time to make a separate list, but if
you ask for the slides, every one of the
items there is named and in most cases
the the URL is just either.com or.ai
with the name. So it&#39;s cling.ai.
Tony, I have a question, please. So I I
find that I use my phone a lot more for
AIGBT and like quick little things I
want to do. turn a photo when edited and
that kind of thing. Am I losing out much
by just using the app version of these
versus the the URL?
I think you&#39;re very brave.
I wouldn&#39;t try doing this kind of stuff
on a phone. There are people who do and
they make it work, but you just got so
much more control when you&#39;re doing it
on a laptop or a desktop.
But I salute your bravery.
Thank you. I appreciate it. It&#39;s much
more It&#39;s much more mobile. I&#39;m much
more mobile with my phone than I am with
and like you&#39;re waiting somewhere. You
just pick it up.
Yeah. It&#39;s difficult to put your desktop
in a backsack and a backpack and walk
around with it.
Can you hear me any better now?
not really.
What are you using for a microphone if
[Laughter]
It&#39;s part of my headset or it&#39;s supposed
Oh, that that explains it. They are
notoriously awful.
Okay, I&#39;ll have to
Yeah, get yourself a microphone.
I will.
I even don&#39;t have a microphone. I just
have my laptop and it&#39;s a microphone
integrated microphone and I think you
should hear hear me well. Right.
Yeah. We also hear a lot of your room
but it&#39;s okay.
Certainly better than a headset.
Tony, another question for you. I think
I asked this before in terms of a little
It&#39;s great to have all those tools, but
I find that I become overwhelmed because
there are so many of them and then time
goes by, you go to work and you forget.
So are you planning on putting like some
sort of like class together where there
would be like a component of
instruction, a component of practice and
then a component of sort like you know
maybe coaching or mentorship through
Yeah, we&#39;ve actually had in the last
month we&#39;ve had two of those where
people in the community they put their
questions into the community and then I
answered all those questions and
demonstrated
those programs. We&#39;re going to have
those from time to time. But also,
there&#39;s a section in the community where
we&#39;ve broken down the key ones. There
are 60,000 tools out there. How many do
you actually need? Maybe six. And we&#39;ve
broken down the most important ones and
done five minute starter videos for
those most important ones. And we&#39;ll
continue to do that and add more. But
there are going to be at least one maybe
two sessions a month where we just
answer people&#39;s questions in terms of
what they actually want to learn and
want to what they want to see
demonstrated.
For sure.
By the way, one of the good things about
a tool like Wavespeed, which is $10 a
month and gives you access to most all
the video generators and image
generators, is you can very
inexpensively try them all and see which
is the one that really works best for
you. And then you go and subscribe to
that one because you know that&#39;s the one
that&#39;s best for you
because what&#39;s best for you may not be
best for Frederick or whoever else.
because everybody needs different
Hey Tony, I got a question.
Hey Dan,
you me you mentioned Etsy and I think
ideogiogram,
however you pronounce it, makes such
incredible images. Do you see a lot of
people making Etsy products using
ideoggram?
Absolutely.
Absolutely. And people are selling AI
art on Etsy and selling it to stock
media libraries and even selling for
millions of dollars at Sabes. Any other
questions before we wrap up?
No, I just had a comment, you know, as
as as I uh sort of like look at the the
amazing power that AI has and stuff like
that. I&#39;m wondering how can I recognize
like something that is genuine now
versus something that is AI? Are they
like some telltale um sort of like signs
because you know pretty much so for
example you show the image of like
Michael Jackson and I forget her name
but it&#39;s just amazing. I mean anybody
can create anything that they want and
it&#39;s perfectly believable.
Yeah. But they&#39;re starting to build in
what they call guard rails. And there
are tools now, I think Google has
brought one out where you can ask it, is
this AI or is it real? And it&#39;ll tell
you. But they&#39;re also starting to
require that images put into what&#39;s
called the meta data, the data behind
the image, whether it&#39;s AI generated or
not. Amazon has already implemented
that. You have and and YouTube has
already implemented that. When you
upload a video, you have to say, &#34;Does
it contain AI content?&#34;
So, if I insert myself into some Forest
Gump scenes where he&#39;s inserted himself
already, it&#39;ll know.
Yes. Is this Is this something you&#39;re
[Laughter]
Okay. Thank you all very much for
attending. Was this useful? Was it
something you can use?
That was great. It&#39;s a bit It&#39;s a bit
overwhelming, but thank you. It was very
There&#39;s so many tools out there, you
know, and when you just do like a chat
search or a Google search, you&#39;re left
with like this very long list that by
the time you&#39;ve done the research on
trying to find the list and trying to
find the one, you&#39;ve expended so much
time that you no longer have the time to
do the project that you were thinking of
Yeah, understood. Understood.
That&#39;s why I&#39;m
Thank you so much. Yeah.
Oh, you&#39;re very
Thank you so much, Con. I was looking
for a while and found that I was feeling
completely behind in the curve of what
all the new tools were that came up. I
thought, oh, instead of me trying to
learn it, I&#39;m to wait for the next Tony
Rockliff masterpiece. And here it is.
Thank you so much.
You&#39;re very welcome. Thank you, Herman.
Thank you so much, Tony.
You&#39;re so welcome, Marley. I&#39;m Claudine.
Thank you. Have a good night.
You too.
Thank you, Tony. Absolutely gobsmacking
as usual.
Oh, thank you.
Appreciate it.
Okay, I&#39;m just saving the chat and then
I will close down the meeting.
Thank you. It was excellent.
Oh, thanks. Appreciate it.
Okay. All right. So, I&#39;m going to close
it down now. Thank you so much for being
very attentive and very pleasant
</textarea>
        </div>

        <div class="mt-8">
          <div class="flex flex-col sm:flex-row sm:justify-between sm:items-center gap-4">
            <a href="../summaries/index.html" class="border-2 border-blue-400 text-blue-400 px-6 py-2 rounded-lg font-medium hover:bg-blue-600 hover:text-white transition duration-300 text-center">
              ← All Summaries
            </a>
            <div class="flex flex-col sm:flex-row sm:items-center gap-4">
              <a href="https://youtube.com/watch?v=t0FEWtQAZ8E" target="_blank" class="bg-red-600 text-white px-4 py-2 rounded-lg font-medium hover:bg-red-700 transition duration-300 text-center">
                Watch on YouTube
              </a>
            </div>
          </div>
        </div>
      </div>
    </section>

    
    <footer class="bg-black text-white py-8">
      <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center">
          <p class="text-gray-400">&copy; 2024 PodPapyrus. All rights reserved.</p>
        </div>
      </div>
    </footer>
  </body>
</html>
